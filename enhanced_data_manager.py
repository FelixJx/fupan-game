#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆæ•°æ®ç®¡ç†å™¨ - å¤šæ•°æ®æºèåˆæ™ºèƒ½å¤ç›˜ç³»ç»Ÿ
åŸºäºåƒç‰›å“¥å¤ç›˜æ–¹æ³•è®º + è¯¦ç»†éœ€æ±‚æ–‡æ¡£å®ç°
"""

import logging
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import pandas as pd
import json

class EnhancedDataManager:
    """
    å¢å¼ºç‰ˆæ•°æ®ç®¡ç†å™¨
    
    é›†æˆæ•°æ®æºï¼š
    1. Tushare Pro - ä¸»è¦é‡‘èæ•°æ®æº
    2. AKShare - å®æ—¶å¸‚åœºæ•°æ® 
    3. Excelæ•°æ® - ç”¨æˆ·å†å²å¤ç›˜æ•°æ®
    4. ä¸œæ–¹è´¢å¯ŒAPI - æ¿å—è½®åŠ¨æ•°æ®
    5. äº‹ä»¶æ—¥å†æ•°æ® - æ”¿ç­–ã€ä¼šè®®ã€è´¢æŠ¥
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.data_cache = {}
        self.last_update = {}
        
        # æ•°æ®æºæƒé‡é…ç½®ï¼ˆæ ¹æ®å¯é æ€§å’Œå®Œæ•´æ€§ï¼‰
        self.source_weights = {
            'excel': 1.0,      # æœ€é«˜æƒé‡ï¼šç”¨æˆ·å†å²æ•°æ®
            'tushare': 0.9,    # é«˜æƒé‡ï¼šä¸“ä¸šé‡‘èæ•°æ®
            'akshare': 0.8,    # ä¸­é«˜æƒé‡ï¼šå®æ—¶æ•°æ®
            'eastmoney': 0.7,  # ä¸­æƒé‡ï¼šæ¿å—æ•°æ®
            'mock': 0.3        # ä½æƒé‡ï¼šæ¨¡æ‹Ÿæ•°æ®
        }
        
    async def get_comprehensive_market_data(self, date_str: str = None) -> Dict[str, Any]:
        """
        è·å–ç»¼åˆå¸‚åœºæ•°æ® - å®ç°åƒç‰›å“¥å¤ç›˜æ–¹æ³•è®ºæ ¸å¿ƒæ•°æ®éœ€æ±‚
        """
        if not date_str:
            date_str = datetime.now().strftime('%Y-%m-%d')
            
        cache_key = f"market_data_{date_str}"
        
        # æ£€æŸ¥ç¼“å­˜
        if self._is_cache_valid(cache_key):
            self.logger.info(f"âœ… ä½¿ç”¨ç¼“å­˜æ•°æ®: {cache_key}")
            return self.data_cache[cache_key]
        
        # å¤šæ•°æ®æºèåˆ
        market_data = await self._fusion_market_data(date_str)
        
        # ç¼“å­˜ç»“æœ
        self.data_cache[cache_key] = market_data
        self.last_update[cache_key] = datetime.now()
        
        return market_data
    
    async def _fusion_market_data(self, date_str: str) -> Dict[str, Any]:
        """æ•°æ®æºèåˆç®—æ³• - æ ¹æ®æƒé‡å’Œå¯ç”¨æ€§æ™ºèƒ½é€‰æ‹©"""
        
        # 1. åƒç‰›å“¥å…­æ­¥å¤ç›˜æ³•æ•°æ®ç»“æ„
        fusion_result = {
            "step1_market_overview": {},
            "step2_risk_scan": {},
            "step3_opportunity_scan": {},
            "step4_capital_verification": {},
            "step5_logic_check": {},
            "step6_portfolio_management": {},
            "metadata": {
                "date": date_str,
                "data_sources_used": [],
                "fusion_confidence": 0.0,
                "qianniu_signals": []
            }
        }
        
        # 2. å¤šæ•°æ®æºå¹¶è¡Œè·å–
        data_sources = await self._parallel_data_fetch(date_str)
        
        # 3. ç¬¬ä¸€æ­¥ï¼šå¸‚åœºé¸Ÿç° (åƒç‰›å“¥æ ¸å¿ƒ)
        fusion_result["step1_market_overview"] = self._fuse_market_overview(data_sources)
        
        # 4. ç¬¬äºŒæ­¥ï¼šé£é™©æ‰«æ
        fusion_result["step2_risk_scan"] = self._fuse_risk_analysis(data_sources)
        
        # 5. ç¬¬ä¸‰æ­¥ï¼šæœºä¼šæ‰«æ
        fusion_result["step3_opportunity_scan"] = self._fuse_opportunity_analysis(data_sources)
        
        # 6. ç¬¬å››æ­¥ï¼šèµ„é‡‘éªŒè¯
        fusion_result["step4_capital_verification"] = self._fuse_capital_analysis(data_sources)
        
        # 7. ç¬¬äº”æ­¥ï¼šé€»è¾‘æ ¸å¯¹
        fusion_result["step5_logic_check"] = self._fuse_logic_analysis(data_sources, date_str)
        
        # 8. ç¬¬å…­æ­¥ï¼šæ ‡è®°åˆ†ç»„
        fusion_result["step6_portfolio_management"] = self._fuse_portfolio_signals(data_sources)
        
        # 9. å…ƒæ•°æ®ç»Ÿè®¡
        fusion_result["metadata"] = self._calculate_fusion_metadata(data_sources)
        
        return fusion_result
    
    async def _parallel_data_fetch(self, date_str: str) -> Dict[str, Any]:
        """å¹¶è¡Œè·å–å¤šæ•°æ®æºæ•°æ® - é›†æˆçœŸå®æ•°æ®æº"""
        
        self.logger.info(f"ğŸ“¡ å¼€å§‹è·å–{date_str}çš„å¤šæºæ•°æ®...")
        
        # å°è¯•è·å–çœŸå®æ•°æ®ï¼Œå¤±è´¥æ—¶ä½¿ç”¨å¤‡ç”¨æ•°æ®
        data_sources = {}
        
        try:
            # ä¼˜å…ˆä½¿ç”¨çœŸå®æ•°æ®æº
            data_sources = {
                "tushare": self._get_real_tushare_data(date_str),
                "akshare": self._get_real_akshare_data(date_str),
                "excel": self._get_real_excel_data(date_str),
                "eastmoney": self._get_real_eastmoney_data(date_str),
                "events": self._simulate_event_data(date_str)  # äº‹ä»¶æ•°æ®æš‚æ—¶ä½¿ç”¨æ¨¡æ‹Ÿ
            }
            
            self.logger.info("âœ… çœŸå®æ•°æ®æºé›†æˆæˆåŠŸ")
            
        except Exception as e:
            self.logger.error(f"âŒ çœŸå®æ•°æ®æºè·å–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®: {e}")
            
            # å¤‡ç”¨ï¼šä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            data_sources = {
                "tushare": self._simulate_tushare_data(date_str),
                "akshare": self._simulate_akshare_data(date_str),
                "excel": self._simulate_excel_data(date_str),
                "eastmoney": self._simulate_eastmoney_data(date_str),
                "events": self._simulate_event_data(date_str)
            }
            
        return data_sources
    
    def _fuse_market_overview(self, data_sources: Dict) -> Dict[str, Any]:
        """èåˆå¸‚åœºé¸Ÿç°æ•°æ® - åƒç‰›å“¥ç¬¬ä¸€æ­¥"""
        
        # ä¼˜å…ˆçº§ï¼šExcel > Tushare > AKShare > æ¨¡æ‹Ÿ
        market_overview = {}
        
        # åŸºç¡€æŒ‡æ ‡èåˆ
        if data_sources.get('excel'):
            excel_data = data_sources['excel'].get('market_overview', {})
            market_overview.update({
                "limit_up_count": excel_data.get('limit_up_count', 0),
                "limit_down_count": excel_data.get('limit_down_count', 0),
                "consecutive_boards": excel_data.get('consecutive_boards', 0),
                "primary_source": "excel"
            })
        
        # Tushareè¡¥å……ç²¾ç¡®æ•°æ®
        if data_sources.get('tushare'):
            tushare_data = data_sources['tushare']
            market_overview.update({
                "market_indices": tushare_data.get('indices', {}),
                "volume_data": tushare_data.get('volume_stats', {}),
                "secondary_source": "tushare"
            })
        
        # åƒç‰›å“¥æ ¸å¿ƒåˆ¤æ–­é€»è¾‘
        limit_up = market_overview.get('limit_up_count', 0)
        limit_down = market_overview.get('limit_down_count', 0)
        
        market_overview.update({
            "qianniu_market_phase": self._determine_market_phase(limit_up, limit_down),
            "emotion_lag_signal": self._calculate_emotion_lag(limit_up, limit_down),
            "first_mover_advantage": limit_up > 30 and limit_down < 10,
            "market_breadth": "good" if limit_up > limit_down * 2 else "weak"
        })
        
        return market_overview
    
    def _fuse_risk_analysis(self, data_sources: Dict) -> Dict[str, Any]:
        """èåˆé£é™©æ‰«ææ•°æ® - åƒç‰›å“¥ç¬¬äºŒæ­¥"""
        
        risk_analysis = {
            "decline_stocks": [],
            "risk_sectors": [],
            "volume_shrinkage": False,
            "systemic_risk_level": "low"
        }
        
        # AKShareå®æ—¶è·Œå¹…æ•°æ®
        if data_sources.get('akshare'):
            akshare_data = data_sources['akshare']
            risk_analysis.update({
                "decline_ranking": akshare_data.get('decline_rank', [])[:20],
                "limit_down_analysis": akshare_data.get('limit_down_stocks', [])
            })
        
        # é£é™©è¯„çº§ç®—æ³•
        limit_down_count = data_sources.get('excel', {}).get('market_overview', {}).get('limit_down_count', 0)
        if limit_down_count > 50:
            risk_analysis["systemic_risk_level"] = "high"
        elif limit_down_count > 20:
            risk_analysis["systemic_risk_level"] = "medium"
        
        return risk_analysis
    
    def _fuse_opportunity_analysis(self, data_sources: Dict) -> Dict[str, Any]:
        """èåˆæœºä¼šæ‰«ææ•°æ® - åƒç‰›å“¥ç¬¬ä¸‰æ­¥"""
        
        opportunity_analysis = {
            "hot_sectors": [],
            "leading_stocks": [],
            "rotation_signals": [],
            "momentum_stocks": []
        }
        
        # ä¸œæ–¹è´¢å¯Œæ¿å—æ•°æ®
        if data_sources.get('eastmoney'):
            eastmoney_data = data_sources['eastmoney']
            opportunity_analysis.update({
                "concept_ranking": eastmoney_data.get('concept_boards', [])[:10],
                "sector_momentum": eastmoney_data.get('sector_strength', {})
            })
        
        # AKShareæ¶¨å¹…æ¦œ
        if data_sources.get('akshare'):
            akshare_data = data_sources['akshare']
            opportunity_analysis.update({
                "gain_ranking": akshare_data.get('gain_rank', [])[:20],
                "volume_price_signals": akshare_data.get('volume_price_analysis', [])
            })
        
        return opportunity_analysis
    
    def _fuse_capital_analysis(self, data_sources: Dict) -> Dict[str, Any]:
        """èåˆèµ„é‡‘éªŒè¯æ•°æ® - åƒç‰›å“¥ç¬¬å››æ­¥"""
        
        capital_analysis = {
            "fund_flow_direction": "neutral",
            "main_capital_sectors": [],
            "volume_leaders": [],
            "institutional_behavior": "wait_and_see"
        }
        
        # Tushareèµ„é‡‘æµå‘æ•°æ®
        if data_sources.get('tushare'):
            tushare_data = data_sources['tushare']
            capital_analysis.update({
                "market_fund_flow": tushare_data.get('money_flow', {}),
                "sector_fund_ranking": tushare_data.get('sector_money_flow', [])
            })
        
        # AKShareé¾™è™æ¦œæ•°æ®
        if data_sources.get('akshare'):
            akshare_data = data_sources['akshare']
            capital_analysis.update({
                "lhb_analysis": akshare_data.get('lhb_data', []),
                "fund_flow_ranking": akshare_data.get('fund_flow', [])[:10]
            })
        
        return capital_analysis
    
    def _fuse_logic_analysis(self, data_sources: Dict, date_str: str) -> Dict[str, Any]:
        """èåˆé€»è¾‘æ ¸å¯¹æ•°æ® - åƒç‰›å“¥ç¬¬äº”æ­¥"""
        
        logic_analysis = {
            "policy_correlation": [],
            "industry_events": [],
            "macro_alignment": "neutral",
            "sector_logic_strength": {}
        }
        
        # äº‹ä»¶é©±åŠ¨æ•°æ®
        if data_sources.get('events'):
            events_data = data_sources['events']
            logic_analysis.update({
                "upcoming_events": events_data.get('upcoming_events', []),
                "policy_expectations": events_data.get('policy_calendar', []),
                "earnings_calendar": events_data.get('earnings_events', [])
            })
        
        # åŸºäºéœ€æ±‚æ–‡æ¡£ä¸­çš„äº‹ä»¶æ—¥å†æ•°æ®
        sample_events = self._get_sample_event_calendar()
        logic_analysis["event_driven_opportunities"] = sample_events
        
        return logic_analysis
    
    def _fuse_portfolio_signals(self, data_sources: Dict) -> Dict[str, Any]:
        """èåˆæŠ•èµ„ç»„åˆä¿¡å· - åƒç‰›å“¥ç¬¬å…­æ­¥"""
        
        portfolio_signals = {
            "recommended_sectors": [],
            "watch_list": [],
            "exit_signals": [],
            "position_suggestions": []
        }
        
        # ç»¼åˆæ‰€æœ‰æ•°æ®æºç”ŸæˆæŠ•èµ„å»ºè®®
        hot_sectors = []
        if data_sources.get('eastmoney'):
            hot_sectors.extend(data_sources['eastmoney'].get('concept_boards', [])[:5])
        
        portfolio_signals.update({
            "recommended_sectors": hot_sectors,
            "strategy_suggestion": "æ ¹æ®æ¿å—è½®åŠ¨é€‰æ‹©é¾™å¤´è‚¡",
            "risk_control": "æ§åˆ¶å•ä¸€æ¿å—ä»“ä½ä¸è¶…è¿‡30%",
            "time_horizon": "çŸ­æœŸ1-3å¤©ï¼Œä¸­æœŸ1-2å‘¨"
        })
        
        return portfolio_signals
    
    def _calculate_fusion_metadata(self, data_sources: Dict) -> Dict[str, Any]:
        """è®¡ç®—èåˆå…ƒæ•°æ®"""
        
        sources_used = [source for source, data in data_sources.items() if data]
        confidence = sum(self.source_weights.get(source, 0.5) for source in sources_used) / len(sources_used) if sources_used else 0.0
        
        return {
            "data_sources_used": sources_used,
            "fusion_confidence": round(confidence, 2),
            "last_update": datetime.now().isoformat(),
            "data_quality": "high" if confidence > 0.8 else "medium" if confidence > 0.6 else "low"
        }
    
    def _determine_market_phase(self, limit_up: int, limit_down: int) -> str:
        """åƒç‰›å“¥å¸‚åœºé˜¶æ®µåˆ¤æ–­"""
        ratio = limit_up / (limit_up + limit_down + 1)  # é¿å…é™¤0
        
        if ratio > 0.8 and limit_up > 50:
            return "ç–¯ç‹‚æœŸ"
        elif ratio > 0.6 and limit_up > 30:
            return "äº¢å¥‹æœŸ"
        elif ratio > 0.4:
            return "å¹³è¡¡æœŸ"
        elif ratio > 0.2:
            return "ä½è¿·æœŸ"
        else:
            return "ææ…ŒæœŸ"
    
    def _calculate_emotion_lag(self, limit_up: int, limit_down: int) -> Dict[str, Any]:
        """è®¡ç®—æƒ…ç»ªæ»åæŒ‡æ ‡"""
        return {
            "price_lead_emotion": limit_up > 40,  # ä»·æ ¼é¢†å…ˆæƒ…ç»ª
            "emotion_catching_up": limit_up > 20 and limit_down < 10,  # æƒ…ç»ªè·Ÿä¸Š
            "lag_days_estimate": 2 if limit_up > 30 else 1,
            "signal_strength": "strong" if limit_up > 40 else "medium" if limit_up > 20 else "weak"
        }
    
    def _get_sample_event_calendar(self) -> List[Dict]:
        """åŸºäºéœ€æ±‚æ–‡æ¡£çš„ç¤ºä¾‹äº‹ä»¶æ—¥å†"""
        return [
            {
                "date": "2025-07-31",
                "event": "ç¬¬2å±Šä¸­å›½å›½é™…æ•°å­—ä¸æ™ºèƒ½æ±½è½¦å±•è§ˆä¼š",
                "sector": "æ•°å­—è´§å¸",
                "importance": "high",
                "expected_impact": "positive"
            },
            {
                "date": "2025-08-14", 
                "event": "ç¬¬26å±Šç”µå­ç§‘æŠ€ä¸æœªæ¥æˆ˜ç•¥ä¼šè®®",
                "sector": "åŠå¯¼ä½“",
                "importance": "high",
                "expected_impact": "positive"
            },
            {
                "date": "2025-08-17",
                "event": "2025å…¨çƒæ™ºæ…§æ•™è‚²å¤§ä¼š", 
                "sector": "åœ¨çº¿æ•™è‚²",
                "importance": "medium",
                "expected_impact": "positive"
            }
        ]
    
    # é›†æˆçœŸå®æ•°æ®æºæ–¹æ³•
    def _get_real_tushare_data(self, date_str: str) -> Dict:
        """è·å–TushareçœŸå®æ•°æ®"""
        try:
            from real_market_data import RealMarketDataFetcher
            fetcher = RealMarketDataFetcher(self.tushare_token if hasattr(self, 'tushare_token') else None)
            
            # è·å–çœŸå®æ¶¨è·Œåœæ•°æ®
            limit_data = fetcher.get_today_limit_data(date_str)
            
            return {
                "indices": limit_data.get("market_overview", {}).get("main_indices", {}),
                "volume_stats": {
                    "total_volume": limit_data.get("market_overview", {}).get("total_amount", 1.15e12),
                    "total_stocks": limit_data.get("market_overview", {}).get("total_stocks", 5000)
                },
                "limit_data": limit_data,
                "money_flow": {"net_inflow": 5.2e9}  # éœ€è¦è¿›ä¸€æ­¥é›†æˆèµ„é‡‘æµå‘API
            }
        except Exception as e:
            self.logger.warning(f"TushareçœŸå®æ•°æ®è·å–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®: {e}")
            return self._simulate_tushare_data(date_str)
    
    def _get_real_akshare_data(self, date_str: str) -> Dict:
        """è·å–AKShareçœŸå®æ•°æ®"""
        try:
            from real_market_data import RealMarketDataFetcher
            from news_analyzer import NewsAnalyzer
            
            fetcher = RealMarketDataFetcher()
            analyzer = NewsAnalyzer()
            
            # è·å–çœŸå®æ¶¨è·Œåœæ•°æ®
            limit_data = fetcher.get_today_limit_data(date_str)
            
            # å¤„ç†æ¶¨åœè‚¡ç¥¨æ•°æ®
            gain_rank = []
            for stock in limit_data.get("limit_up_stocks", [])[:10]:
                reason = analyzer.analyze_stock_limit_reason(
                    stock["code"], stock["name"], "up"
                )
                gain_rank.append({
                    "name": stock["name"],
                    "code": stock["code"],
                    "change": stock["change_pct"],
                    "reason": reason,
                    "amount": stock["amount"],
                    "sector": stock["sector"]
                })
            
            # å¤„ç†è·Œåœè‚¡ç¥¨æ•°æ®
            decline_rank = []
            for stock in limit_data.get("limit_down_stocks", [])[:10]:
                reason = analyzer.analyze_stock_limit_reason(
                    stock["code"], stock["name"], "down"
                )
                decline_rank.append({
                    "name": stock["name"],
                    "code": stock["code"],
                    "change": stock["change_pct"],
                    "reason": reason,
                    "amount": stock["amount"],
                    "sector": stock["sector"]
                })
            
            return {
                "gain_rank": gain_rank,
                "decline_rank": decline_rank,
                "fund_flow": [
                    {"name": "äººå·¥æ™ºèƒ½", "net_inflow": 2.1e8}
                ],
                "limit_up_stocks": limit_data.get("limit_up_stocks", []),
                "limit_down_stocks": limit_data.get("limit_down_stocks", [])
            }
            
        except Exception as e:
            self.logger.warning(f"AKShareçœŸå®æ•°æ®è·å–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®: {e}")
            return self._simulate_akshare_data(date_str)
    
    def _get_real_excel_data(self, date_str: str) -> Dict:
        """è·å–ExcelçœŸå®æ•°æ®"""
        try:
            from real_market_data import RealMarketDataFetcher
            fetcher = RealMarketDataFetcher()
            
            # è·å–çœŸå®å¸‚åœºæ•°æ®
            limit_data = fetcher.get_today_limit_data(date_str)
            
            return {
                "market_overview": {
                    "limit_up_count": limit_data.get("limit_up_count", 0),
                    "limit_down_count": limit_data.get("limit_down_count", 0),
                    "up_count": limit_data.get("market_overview", {}).get("up_stocks", 2850),
                    "down_count": limit_data.get("market_overview", {}).get("down_stocks", 1650),
                    "total_volume": limit_data.get("market_overview", {}).get("total_amount", 1.15e12),
                    "consecutive_boards": self._calculate_consecutive_boards(limit_data.get("limit_up_stocks", [])),
                    "blow_up_rate": 0.15
                }
            }
        except Exception as e:
            self.logger.warning(f"Excelæ•°æ®å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®: {e}")
            return self._simulate_excel_data(date_str)
    
    def _get_real_eastmoney_data(self, date_str: str) -> Dict:
        """è·å–ä¸œæ–¹è´¢å¯ŒçœŸå®æ•°æ®"""
        try:
            from real_market_data import RealMarketDataFetcher
            fetcher = RealMarketDataFetcher()
            
            # è·å–çœŸå®æ¶¨åœæ•°æ®åˆ†ææ¿å—
            limit_data = fetcher.get_today_limit_data(date_str)
            concept_boards = self._analyze_sector_strength(limit_data.get("limit_up_stocks", []))
            
            return {
                "concept_boards": concept_boards,
                "sector_strength": {board["name"]: board["strength"] for board in concept_boards}
            }
        except Exception as e:
            self.logger.warning(f"ä¸œæ–¹è´¢å¯Œæ•°æ®è·å–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®: {e}")
            return self._simulate_eastmoney_data(date_str)
    
    def _calculate_consecutive_boards(self, limit_up_stocks: List) -> int:
        """è®¡ç®—è¿æ¿æ•°é‡"""
        # ç®€åŒ–ç‰ˆè¿æ¿è®¡ç®—
        consecutive_count = 0
        for stock in limit_up_stocks:
            # è¿™é‡Œåº”è¯¥æŸ¥è¯¢å†å²æ•°æ®è®¡ç®—çœŸå®è¿æ¿æ•°
            # æš‚æ—¶ä½¿ç”¨æ¨¡æ‹Ÿé€»è¾‘
            if stock.get("change_pct", 0) >= 10:
                consecutive_count += 1
        return min(consecutive_count, 20)  # é™åˆ¶æœ€å¤§è¿æ¿æ•°
    
    def _analyze_sector_strength(self, limit_up_stocks: List) -> List[Dict]:
        """åˆ†ææ¿å—å¼ºåº¦"""
        sector_stats = {}
        
        for stock in limit_up_stocks:
            sector = stock.get("sector", "å…¶ä»–")
            if sector not in sector_stats:
                sector_stats[sector] = {
                    "name": sector,
                    "stock_count": 0,
                    "total_amount": 0,
                    "avg_change": 0,
                    "strength": 0
                }
            
            sector_stats[sector]["stock_count"] += 1
            sector_stats[sector]["total_amount"] += stock.get("amount", 0)
            sector_stats[sector]["avg_change"] += stock.get("change_pct", 0)
        
        # è®¡ç®—æ¿å—å¼ºåº¦
        for sector, stats in sector_stats.items():
            if stats["stock_count"] > 0:
                stats["avg_change"] /= stats["stock_count"]
                stats["strength"] = min(stats["stock_count"] * 0.1 + stats["avg_change"] * 0.01, 1.0)
        
        # æŒ‰å¼ºåº¦æ’åº
        sorted_sectors = sorted(sector_stats.values(), key=lambda x: x["strength"], reverse=True)
        return sorted_sectors[:10]
    
    # ä¿ç•™å¤‡ç”¨æ¨¡æ‹Ÿæ•°æ®æ–¹æ³•
    def _simulate_tushare_data(self, date_str: str) -> Dict:
        return {
            "indices": {
                "ä¸Šè¯æŒ‡æ•°": {"close": 3245.67, "change": -1.2},
                "æ·±è¯æˆæŒ‡": {"close": 12456.32, "change": 0.8},
                "åˆ›ä¸šæ¿æŒ‡": {"close": 2876.45, "change": 1.5}
            },
            "volume_stats": {"total_volume": 1.15e12},
            "money_flow": {"net_inflow": 5.2e9}
        }
    
    def _simulate_akshare_data(self, date_str: str) -> Dict:
        return {
            "gain_rank": [
                {"name": "æ¯”äºšè¿ª", "change": 10.01, "reason": "æ–°èƒ½æºæ”¿ç­–"},
                {"name": "å®å¾·æ—¶ä»£", "change": 9.98, "reason": "ç”µæ± æŠ€æœ¯çªç ´"}
            ],
            "decline_rank": [
                {"name": "æŸåœ°äº§è‚¡", "change": -9.95, "reason": "æ”¿ç­–è°ƒæ§"}
            ],
            "fund_flow": [
                {"name": "äººå·¥æ™ºèƒ½", "net_inflow": 2.1e8}
            ]
        }
    
    def _simulate_excel_data(self, date_str: str) -> Dict:
        return {
            "market_overview": {
                "limit_up_count": 45,
                "limit_down_count": 8,
                "consecutive_boards": 12,
                "blow_up_rate": 0.15
            }
        }
    
    def _simulate_eastmoney_data(self, date_str: str) -> Dict:
        return {
            "concept_boards": [
                {"name": "äººå·¥æ™ºèƒ½", "change": 3.2, "stock_count": 156},
                {"name": "æ–°èƒ½æºæ±½è½¦", "change": 2.8, "stock_count": 98}
            ],
            "sector_strength": {"AIæ¦‚å¿µ": 0.85, "æ–°èƒ½æº": 0.78}
        }
    
    def _simulate_event_data(self, date_str: str) -> Dict:
        return {
            "upcoming_events": self._get_sample_event_calendar(),
            "policy_calendar": [
                {"date": "2025-08-10", "event": "å¤®è¡Œè´§å¸æ”¿ç­–ä¼šè®®"}
            ]
        }
    
    def _is_cache_valid(self, cache_key: str, max_age_minutes: int = 5) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if cache_key not in self.data_cache:
            return False
        
        last_update = self.last_update.get(cache_key)
        if not last_update:
            return False
        
        age = datetime.now() - last_update
        return age.total_seconds() < max_age_minutes * 60

    def get_data_source_status(self) -> Dict[str, Any]:
        """è·å–æ•°æ®æºçŠ¶æ€æŠ¥å‘Š"""
        return {
            "available_sources": list(self.source_weights.keys()),
            "source_weights": self.source_weights,
            "cache_status": {
                "cached_items": len(self.data_cache),
                "last_updates": {k: v.isoformat() for k, v in self.last_update.items()}
            },
            "system_status": "operational",
            "last_health_check": datetime.now().isoformat()
        }

# ç¤ºä¾‹ä½¿ç”¨
async def main():
    """æ¼”ç¤ºå¤šæ•°æ®æºèåˆåŠŸèƒ½"""
    manager = EnhancedDataManager()
    
    print("ğŸš€ å¢å¼ºç‰ˆæ•°æ®ç®¡ç†å™¨æ¼”ç¤º")
    print("=" * 50)
    
    # è·å–ç»¼åˆå¸‚åœºæ•°æ®
    market_data = await manager.get_comprehensive_market_data()
    
    print(f"ğŸ“Š å¸‚åœºæ¦‚è§ˆ (åƒç‰›å“¥ç¬¬ä¸€æ­¥):")
    overview = market_data["step1_market_overview"]
    print(f"  æ¶¨åœæ•°: {overview.get('limit_up_count', 'N/A')}")
    print(f"  è·Œåœæ•°: {overview.get('limit_down_count', 'N/A')}")
    print(f"  å¸‚åœºé˜¶æ®µ: {overview.get('qianniu_market_phase', 'N/A')}")
    print(f"  å…ˆæ‰‹ä¼˜åŠ¿: {overview.get('first_mover_advantage', False)}")
    
    print(f"\nğŸš¨ é£é™©æ‰«æ (åƒç‰›å“¥ç¬¬äºŒæ­¥):")
    risk = market_data["step2_risk_scan"]
    print(f"  ç³»ç»Ÿæ€§é£é™©: {risk.get('systemic_risk_level', 'N/A')}")
    
    print(f"\nğŸ¯ æœºä¼šæ‰«æ (åƒç‰›å“¥ç¬¬ä¸‰æ­¥):")
    opportunity = market_data["step3_opportunity_scan"]
    print(f"  çƒ­é—¨æ¦‚å¿µ: {len(opportunity.get('concept_ranking', []))} ä¸ª")
    
    print(f"\nğŸ’° èµ„é‡‘éªŒè¯ (åƒç‰›å“¥ç¬¬å››æ­¥):")
    capital = market_data["step4_capital_verification"]
    print(f"  èµ„é‡‘æµå‘: {capital.get('fund_flow_direction', 'N/A')}")
    
    print(f"\nğŸ§  é€»è¾‘æ ¸å¯¹ (åƒç‰›å“¥ç¬¬äº”æ­¥):")
    logic = market_data["step5_logic_check"]
    print(f"  å³å°†ä¸¾è¡Œçš„é‡è¦äº‹ä»¶: {len(logic.get('upcoming_events', []))} ä¸ª")
    
    print(f"\nğŸ“‹ æŠ•èµ„å»ºè®® (åƒç‰›å“¥ç¬¬å…­æ­¥):")
    portfolio = market_data["step6_portfolio_management"]
    print(f"  æ¨èç­–ç•¥: {portfolio.get('strategy_suggestion', 'N/A')}")
    
    print(f"\nğŸ“ˆ èåˆå…ƒæ•°æ®:")
    metadata = market_data["metadata"]
    print(f"  æ•°æ®æº: {', '.join(metadata.get('data_sources_used', []))}")
    print(f"  èåˆä¿¡å¿ƒåº¦: {metadata.get('fusion_confidence', 0)}")
    print(f"  æ•°æ®è´¨é‡: {metadata.get('data_quality', 'N/A')}")
    
    print("\nâœ… å¤šæ•°æ®æºèåˆæ¼”ç¤ºå®Œæˆï¼")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())