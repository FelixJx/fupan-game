#!/usr/bin/env python3
"""
é¢„æµ‹æŒ‘æˆ˜æ¸¸æˆå¼•æ“ - åŸºäºå®æ—¶æ•°æ®çš„æ™ºèƒ½å¤ç›˜é¢„æµ‹ç³»ç»Ÿ
ç”¨æˆ·é€šè¿‡é€‰æ‹©é¢˜é¢„æµ‹æ˜æ—¥å¸‚åœºï¼Œç³»ç»Ÿè‡ªåŠ¨å›æµ‹è¯„åˆ†
"""

import sqlite3
import json
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import logging
import asyncio
from dataclasses import dataclass

@dataclass
class PredictionQuestion:
    """é¢„æµ‹é—®é¢˜æ•°æ®ç»“æ„"""
    question_id: str
    step: int  # 1-6å¯¹åº”åƒç‰›å“¥å…­æ­¥
    question_text: str
    options: List[Dict[str, Any]]
    correct_answer: Optional[str] = None
    ai_analysis: Optional[str] = None
    data_source: Optional[Dict] = None

@dataclass
class UserPrediction:
    """ç”¨æˆ·é¢„æµ‹è®°å½•"""
    user_id: str
    date: str
    question_id: str
    selected_option: str
    confidence: float
    timestamp: datetime

class PredictionGameEngine:
    """é¢„æµ‹æŒ‘æˆ˜æ¸¸æˆå¼•æ“"""
    
    def __init__(self, db_path="prediction_game.db"):
        self.db_path = db_path
        self.logger = logging.getLogger(__name__)
        self.init_database()
        
    def init_database(self):
        """åˆå§‹åŒ–æ¸¸æˆæ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ç”¨æˆ·åŸºç¡€ä¿¡æ¯è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS users (
                user_id TEXT PRIMARY KEY,
                username TEXT NOT NULL,
                total_predictions INTEGER DEFAULT 0,
                correct_predictions INTEGER DEFAULT 0,
                accuracy_rate REAL DEFAULT 0.0,
                total_score INTEGER DEFAULT 0,
                level INTEGER DEFAULT 1,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # æ¯æ—¥é¢„æµ‹é¢˜ç›®è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS daily_questions (
                question_id TEXT PRIMARY KEY,
                date TEXT NOT NULL,
                step INTEGER NOT NULL,
                question_text TEXT NOT NULL,
                options TEXT NOT NULL,
                ai_analysis TEXT,
                market_data TEXT,
                correct_answer TEXT,
                is_verified BOOLEAN DEFAULT FALSE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # ç”¨æˆ·é¢„æµ‹è®°å½•è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS user_predictions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                date TEXT NOT NULL,
                question_id TEXT NOT NULL,
                selected_option TEXT NOT NULL,
                confidence REAL DEFAULT 0.5,
                is_correct BOOLEAN,
                score_earned INTEGER DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users (user_id),
                FOREIGN KEY (question_id) REFERENCES daily_questions (question_id)
            )
        ''')
        
        # æ¯æ—¥æ’è¡Œæ¦œè¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS daily_leaderboard (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                date TEXT NOT NULL,
                user_id TEXT NOT NULL,
                daily_score INTEGER DEFAULT 0,
                daily_accuracy REAL DEFAULT 0.0,
                questions_answered INTEGER DEFAULT 0,
                rank_position INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(date, user_id)
            )
        ''')
        
        # å¸‚åœºéªŒè¯æ•°æ®è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS market_verification (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                date TEXT NOT NULL,
                question_id TEXT NOT NULL,
                prediction_data TEXT,
                actual_data TEXT,
                verification_result TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
    
    async def generate_daily_questions(self, date_str: str, market_data: Dict) -> List[PredictionQuestion]:
        """æ ¹æ®å®æ—¶å¸‚åœºæ•°æ®ç”Ÿæˆæ¯æ—¥é¢„æµ‹é¢˜ç›®"""
        
        questions = []
        
        # ç¬¬ä¸€æ­¥ï¼šå¸‚åœºé¸Ÿç° - æƒ…ç»ªåˆ¤æ–­é¢˜
        q1 = await self._generate_market_overview_question(date_str, market_data)
        questions.append(q1)
        
        # ç¬¬äºŒæ­¥ï¼šé£é™©æ‰«æ - è·Œåœæ¿å—åˆ†æ
        q2 = await self._generate_risk_scan_question(date_str, market_data)
        questions.append(q2)
        
        # ç¬¬ä¸‰æ­¥ï¼šæœºä¼šæ‰«æ - çƒ­é—¨æ¿å—å»¶ç»­æ€§
        q3 = await self._generate_opportunity_question(date_str, market_data)
        questions.append(q3)
        
        # ç¬¬å››æ­¥ï¼šèµ„é‡‘éªŒè¯ - èµ„é‡‘æµå‘é¢„æµ‹
        q4 = await self._generate_capital_question(date_str, market_data)
        questions.append(q4)
        
        # ç¬¬äº”æ­¥ï¼šé€»è¾‘æ ¸å¯¹ - äº‹ä»¶é©±åŠ¨å½±å“
        q5 = await self._generate_logic_question(date_str, market_data)
        questions.append(q5)
        
        # ç¬¬å…­æ­¥ï¼šæ ‡è®°åˆ†ç»„ - æ˜æ—¥æ“ä½œç­–ç•¥
        q6 = await self._generate_portfolio_question(date_str, market_data)
        questions.append(q6)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        await self._save_daily_questions(questions)
        
        return questions
    
    async def _generate_market_overview_question(self, date_str: str, market_data: Dict) -> PredictionQuestion:
        """ç”Ÿæˆå¸‚åœºé¸Ÿç°é¢„æµ‹é¢˜ - å¢å¼ºç‰ˆæ•°æ®å±•ç¤º"""
        
        overview = market_data.get('step1_market_overview', {})
        limit_up = overview.get('limit_up_count', 0)
        limit_down = overview.get('limit_down_count', 0)
        up_count = overview.get('up_count', 2850)  # ä¸Šæ¶¨ä¸ªè‚¡æ•°
        down_count = overview.get('down_count', 1650)  # ä¸‹è·Œä¸ªè‚¡æ•°
        total_volume = overview.get('total_volume', 1.15e12)  # æˆäº¤é¢
        market_phase = overview.get('qianniu_market_phase', 'å¹³è¡¡æœŸ')
        
        # è®¡ç®—è¯¦ç»†å¸‚åœºæŒ‡æ ‡
        total_stocks = up_count + down_count
        up_ratio = (up_count / total_stocks * 100) if total_stocks > 0 else 50
        volume_billion = total_volume / 1e8  # è½¬æ¢ä¸ºäº¿å…ƒ
        
        # AIåˆ†æå½“å‰å¸‚åœºæƒ…ç»ª
        ai_analysis = f"""
        ğŸ“Š **ä»Šæ—¥å¸‚åœºå…¨æ™¯æ•°æ®**ï¼š
        
        ğŸ”¸ **æ¶¨è·Œç»Ÿè®¡**ï¼š
        - æ¶¨åœè‚¡æ•°ï¼š{limit_up}åª  |  è·Œåœè‚¡æ•°ï¼š{limit_down}åª
        - ä¸Šæ¶¨ä¸ªè‚¡ï¼š{up_count}åª  |  ä¸‹è·Œä¸ªè‚¡ï¼š{down_count}åª
        - æ¶¨è·Œæ¯”ä¾‹ï¼š{up_ratio:.1f}% vs {100-up_ratio:.1f}%
        
        ğŸ”¸ **æˆäº¤æ•°æ®**ï¼š
        - æ€»æˆäº¤é¢ï¼š{volume_billion:.0f}äº¿å…ƒ
        - å¸‚åœºæ´»è·ƒåº¦ï¼š{'é«˜' if volume_billion > 10000 else 'ä¸­ç­‰' if volume_billion > 8000 else 'åä½'}
        
        ğŸ”¸ **åƒç‰›å“¥åˆ¤æ–­**ï¼š
        - å¸‚åœºé˜¶æ®µï¼š{market_phase}
        - æƒ…ç»ªæŒ‡æ ‡ï¼š{'å¼ºåŠ¿' if limit_up > 30 else 'ä¸­æ€§' if limit_up > 15 else 'å¼±åŠ¿'}
        
        æ ¹æ®åƒç‰›å“¥"æƒ…ç»ªæ»åä»·æ ¼"ç†è®ºï¼Œå½“å‰æ¶¨åœæ•°é‡{limit_up}åªï¼Œé¢„ç¤ºæ˜æ—¥æƒ…ç»ªå˜åŒ–ã€‚
        å†å²æ•°æ®æ˜¾ç¤ºï¼Œ{market_phase}é˜¶æ®µåçš„æƒ…ç»ªå»¶ç»­æ¦‚ç‡çº¦ä¸º65%ã€‚
        """
        
        question_text = f"ğŸ“ˆ ä»Šæ—¥å¸‚åœºæ•°æ®ï¼šæ¶¨åœ{limit_up}åªï¼Œè·Œåœ{limit_down}åªï¼Œä¸Šæ¶¨{up_count}åªï¼Œä¸‹è·Œ{down_count}åªï¼Œæˆäº¤{volume_billion:.0f}äº¿å…ƒã€‚å¸‚åœºé˜¶æ®µï¼š{market_phase}ã€‚è¯·é¢„æµ‹æ˜æ—¥å¸‚åœºæ•´ä½“æƒ…ç»ªèµ°å‘ï¼š"
        
        options = [
            {"id": "A", "text": "æƒ…ç»ªå°†æ›´åŠ äº¢å¥‹ï¼Œæ¶¨åœè‚¡æ•°é‡å¢åŠ ", "score_weight": 1.0},
            {"id": "B", "text": "æƒ…ç»ªä¿æŒç¨³å®šï¼Œæ¶¨åœè‚¡æ•°é‡æŒå¹³", "score_weight": 0.8},
            {"id": "C", "text": "æƒ…ç»ªå¼€å§‹é™æ¸©ï¼Œæ¶¨åœè‚¡æ•°é‡å‡å°‘", "score_weight": 0.6},
            {"id": "D", "text": "æƒ…ç»ªæ˜æ˜¾è½¬å†·ï¼Œå¸‚åœºè½¬å…¥è°ƒæ•´", "score_weight": 0.4}
        ]
        
        return PredictionQuestion(
            question_id=f"{date_str}_step1",
            step=1,
            question_text=question_text,
            options=options,
            ai_analysis=ai_analysis,
            data_source=overview
        )
    
    async def _generate_risk_scan_question(self, date_str: str, market_data: Dict) -> PredictionQuestion:
        """ç”Ÿæˆé£é™©æ‰«æé¢„æµ‹é¢˜ - å¢å¼ºç‰ˆè·Œåœä¸ªè‚¡åˆ†æ"""
        
        risk_data = market_data.get('step2_risk_scan', {})
        decline_stocks = risk_data.get('decline_ranking', [])[:10]
        risk_level = risk_data.get('systemic_risk_level', 'low')
        
        # æ¨¡æ‹Ÿå…·ä½“è·Œåœä¸ªè‚¡æ•°æ®ï¼ˆå°æ¿é‡‘é¢é«˜çš„ä¸ªè‚¡ï¼‰
        top_limit_down_stocks = [
            {"name": "ä¸‡ç§‘A", "code": "000002", "sector": "æˆ¿åœ°äº§", "å°æ¿é‡‘é¢": "12.5äº¿", "è·ŒåœåŸå› ": "åœ°äº§æ”¿ç­–æ”¶ç´§é¢„æœŸ"},
            {"name": "ä¿åˆ©å‘å±•", "code": "600048", "sector": "æˆ¿åœ°äº§", "å°æ¿é‡‘é¢": "8.3äº¿", "è·ŒåœåŸå› ": "é”€å”®æ•°æ®ä¸åŠé¢„æœŸ"},
            {"name": "æ‹›å•†é“¶è¡Œ", "code": "600036", "sector": "é“¶è¡Œ", "å°æ¿é‡‘é¢": "15.2äº¿", "è·ŒåœåŸå› ": "æ¯å·®æ”¶çª„æ‹…å¿§"},
            {"name": "ä¸­å›½å¹³å®‰", "code": "601318", "sector": "ä¿é™©", "å°æ¿é‡‘é¢": "18.7äº¿", "è·ŒåœåŸå› ": "ç›‘ç®¡æ”¿ç­–è°ƒæ•´"},
            {"name": "æ ¼åŠ›ç”µå™¨", "code": "000651", "sector": "å®¶ç”µ", "å°æ¿é‡‘é¢": "6.8äº¿", "è·ŒåœåŸå› ": "ä¸šç»©ä½äºé¢„æœŸ"}
        ][:3]  # å–å‰3åª
        
        # åˆ†æä¸»è¦ä¸‹è·Œæ¿å—
        sector_impact = {}
        for stock in top_limit_down_stocks:
            sector = stock["sector"]
            if sector not in sector_impact:
                sector_impact[sector] = {"count": 0, "total_amount": 0, "stocks": []}
            sector_impact[sector]["count"] += 1
            sector_impact[sector]["total_amount"] += float(stock["å°æ¿é‡‘é¢"].replace("äº¿", ""))
            sector_impact[sector]["stocks"].append(stock["name"])
        
        # æ‰¾å‡ºå½±å“æœ€å¤§çš„æ¿å—
        main_sector = max(sector_impact.keys(), key=lambda x: sector_impact[x]["total_amount"])
        main_sector_data = sector_impact[main_sector]
        
        # æ„å»ºè¯¦ç»†çš„è‚¡ç¥¨ä¿¡æ¯
        stocks_detail = "\n".join([
            f"â€¢ {stock['name']}({stock['code']}) - {stock['sector']}æ¿å—\n  å°æ¿é‡‘é¢ï¼š{stock['å°æ¿é‡‘é¢']} | è·ŒåœåŸå› ï¼š{stock['è·ŒåœåŸå› ']}"
            for stock in top_limit_down_stocks
        ])
        
        # LLMåˆ†æè·Œåœæ¿å—åŸå› 
        ai_analysis = f"""
        ğŸš¨ **é‡ç‚¹è·Œåœä¸ªè‚¡åˆ†æ**ï¼š
        
        ğŸ“‰ **å°æ¿é‡‘é¢æœ€å¤§çš„è·Œåœè‚¡**ï¼š
        {stocks_detail}
        
        ğŸ”¸ **æ¿å—å½±å“åˆ†æ**ï¼š
        - ä¸»è¦å†²å‡»æ¿å—ï¼š{main_sector}
        - è¯¥æ¿å—è·Œåœè‚¡æ•°ï¼š{main_sector_data['count']}åª
        - ç´¯è®¡å°æ¿èµ„é‡‘ï¼š{main_sector_data['total_amount']:.1f}äº¿å…ƒ
        - å—å½±å“ä¸ªè‚¡ï¼š{', '.join(main_sector_data['stocks'])}
        
        ğŸ”¸ **é£é™©ä¼ å¯¼åˆ†æ**ï¼š
        - ç³»ç»Ÿæ€§é£é™©ç­‰çº§ï¼š{risk_level.upper()}
        - èµ„é‡‘ææ…Œç¨‹åº¦ï¼š{'é«˜' if main_sector_data['total_amount'] > 20 else 'ä¸­ç­‰' if main_sector_data['total_amount'] > 10 else 'å¯æ§'}
        - æ¿å—è¿é”ååº”ï¼š{main_sector}æ¿å—å†…å…¶ä»–ä¸ªè‚¡æ˜æ—¥é¢ä¸´è¡¥è·Œé£é™©
        
        ğŸ”¸ **åƒç‰›å“¥é£é™©åˆ¤æ–­**ï¼š
        å¤§é¢å°æ¿è·Œåœå¾€å¾€ä»£è¡¨ä¸»åŠ›èµ„é‡‘çš„åšå†³ç¦»åœºï¼ŒçŸ­æœŸéš¾ä»¥æ‰­è½¬ã€‚
        ä½†è¿‡åº¦ææ…Œåå¾€å¾€å‡ºç°æŠ€æœ¯æ€§åå¼¹æœºä¼šï¼Œå…³é”®çœ‹æ¿å—åŸºæœ¬é¢æ˜¯å¦å‘ç”Ÿè´¨å˜ã€‚
        """
        
        question_text = f"ğŸš¨ ä»Šæ—¥é‡ç‚¹è·Œåœåˆ†æï¼š{main_sector}æ¿å—å—å†²å‡»æœ€å¤§ï¼Œ{main_sector_data['count']}åªä¸ªè‚¡è·Œåœï¼Œå°æ¿èµ„é‡‘{main_sector_data['total_amount']:.1f}äº¿å…ƒã€‚è¯·é¢„æµ‹è¯¥æ¿å—æ˜æ—¥è¡¨ç°ï¼š"
        
        options = [
            {"id": "A", "text": f"ææ…Œè¿‡åº¦ï¼Œ{main_sector}æ¿å—æŠ€æœ¯æ€§åå¼¹", "score_weight": 1.0},
            {"id": "B", "text": f"ç»§ç»­æ‰¿å‹ï¼Œ{main_sector}æ¿å—å¼±åŠ¿ç›˜æ•´", "score_weight": 0.8},
            {"id": "C", "text": f"ææ…Œè”“å»¶ï¼Œ{main_sector}æ¿å—ç»§ç»­ä¸‹è·Œ", "score_weight": 0.6},
            {"id": "D", "text": f"å´©ç›˜é£é™©ï¼Œ{main_sector}æ¿å—å¤§é¢ç§¯è·Œåœ", "score_weight": 0.4}
        ]
        
        return PredictionQuestion(
            question_id=f"{date_str}_step2",
            step=2,
            question_text=question_text,
            options=options,
            ai_analysis=ai_analysis,
            data_source=risk_data
        )
    
    async def _generate_opportunity_question(self, date_str: str, market_data: Dict) -> PredictionQuestion:
        """ç”Ÿæˆæœºä¼šæ‰«æé¢„æµ‹é¢˜ - å¢å¼ºç‰ˆæ¶¨åœä¸ªè‚¡åˆ†æ"""
        
        opportunity = market_data.get('step3_opportunity_scan', {})
        hot_concepts = opportunity.get('concept_ranking', [])[:5]
        
        # æ¨¡æ‹Ÿå…·ä½“æ¶¨åœä¸ªè‚¡æ•°æ®ï¼ˆå°æ¿é‡‘é¢æœ€å¤§çš„ä¸ªè‚¡ï¼‰
        top_limit_up_stocks = [
            {
                "name": "æ¯”äºšè¿ª", "code": "002594", "sector": "æ–°èƒ½æºæ±½è½¦", 
                "å°æ¿é‡‘é¢": "28.6äº¿", "æ¶¨åœåŸå› ": "åˆ€ç‰‡ç”µæ± æŠ€æœ¯çªç ´", 
                "æ¿å†…æ¶¨åœæ•°": 15, "æœ€é«˜æ¿": "3è¿æ¿"
            },
            {
                "name": "å®å¾·æ—¶ä»£", "code": "300750", "sector": "æ–°èƒ½æºæ±½è½¦", 
                "å°æ¿é‡‘é¢": "35.2äº¿", "æ¶¨åœåŸå› ": "ä¸ç‰¹æ–¯æ‹‰åˆä½œæ·±åŒ–", 
                "æ¿å†…æ¶¨åœæ•°": 15, "æœ€é«˜æ¿": "3è¿æ¿"
            },
            {
                "name": "ç§‘å¤§è®¯é£", "code": "002230", "sector": "äººå·¥æ™ºèƒ½", 
                "å°æ¿é‡‘é¢": "18.7äº¿", "æ¶¨åœåŸå› ": "AIå¤§æ¨¡å‹æ–°çªç ´", 
                "æ¿å†…æ¶¨åœæ•°": 12, "æœ€é«˜æ¿": "5è¿æ¿"
            },
            {
                "name": "æµ·åº·å¨è§†", "code": "002415", "sector": "äººå·¥æ™ºèƒ½", 
                "å°æ¿é‡‘é¢": "22.1äº¿", "æ¶¨åœåŸå› ": "æ™ºèƒ½å®‰é˜²è®¢å•å¢é•¿", 
                "æ¿å†…æ¶¨åœæ•°": 12, "æœ€é«˜æ¿": "5è¿æ¿"
            },
            {
                "name": "è¿ˆç‘åŒ»ç–—", "code": "300760", "sector": "åŒ»ç–—å™¨æ¢°", 
                "å°æ¿é‡‘é¢": "16.8äº¿", "æ¶¨åœåŸå› ": "æ–°äº§å“è·FDAè®¤è¯", 
                "æ¿å†…æ¶¨åœæ•°": 8, "æœ€é«˜æ¿": "2è¿æ¿"
            }
        ][:4]  # å–å‰4åª
        
        # åˆ†ææ¿å—å¼ºåº¦
        sector_strength = {}
        for stock in top_limit_up_stocks:
            sector = stock["sector"]
            if sector not in sector_strength:
                sector_strength[sector] = {
                    "count": 0, "total_amount": 0, "stocks": [], 
                    "max_consecutive": 0, "limit_up_count": 0
                }
            sector_strength[sector]["count"] += 1
            sector_strength[sector]["total_amount"] += float(stock["å°æ¿é‡‘é¢"].replace("äº¿", ""))
            sector_strength[sector]["stocks"].append(stock["name"])
            sector_strength[sector]["limit_up_count"] = stock["æ¿å†…æ¶¨åœæ•°"]
            sector_strength[sector]["max_consecutive"] = stock["æœ€é«˜æ¿"]
        
        # æ‰¾å‡ºæœ€å¼ºæ¿å—
        strongest_sector = max(sector_strength.keys(), key=lambda x: sector_strength[x]["total_amount"])
        strongest_data = sector_strength[strongest_sector]
        
        # æ„å»ºè¯¦ç»†è‚¡ç¥¨ä¿¡æ¯
        stocks_detail = "\n".join([
            f"â€¢ {stock['name']}({stock['code']}) - å°æ¿{stock['å°æ¿é‡‘é¢']}\n  æ¶¨åœåŸå› ï¼š{stock['æ¶¨åœåŸå› ']}"
            for stock in top_limit_up_stocks if stock['sector'] == strongest_sector
        ])
        
        ai_analysis = f"""
        ğŸ”¥ **é‡ç‚¹æ¶¨åœä¸ªè‚¡åˆ†æ**ï¼š
        
        ğŸ“ˆ **å°æ¿é‡‘é¢æœ€å¤§çš„æ¶¨åœè‚¡**ï¼š
        {stocks_detail}
        
        ğŸ”¸ **æ¿å—å¼ºåº¦åˆ†æ**ï¼š
        - é¢†æ¶¨æ¿å—ï¼š{strongest_sector}
        - æ¿å—å†…æ¶¨åœæ•°ï¼š{strongest_data['limit_up_count']}åª
        - æœ€é«˜è¿æ¿æ•°ï¼š{strongest_data['max_consecutive']}
        - ç´¯è®¡å°æ¿èµ„é‡‘ï¼š{strongest_data['total_amount']:.1f}äº¿å…ƒ
        - æ ¸å¿ƒé¾™å¤´è‚¡ï¼š{', '.join(strongest_data['stocks'])}
        
        ğŸ”¸ **æ¿å—è½®åŠ¨åˆ†æ**ï¼š
        - èµ„é‡‘æµå…¥å¼ºåº¦ï¼š{'æå¼º' if strongest_data['total_amount'] > 50 else 'å¼º' if strongest_data['total_amount'] > 30 else 'ä¸­ç­‰'}
        - å¸‚åœºå…³æ³¨åº¦ï¼š{strongest_data['limit_up_count']}åªæ¶¨åœæ˜¾ç¤ºé«˜åº¦å…³æ³¨
        - æŒç»­æ€§é¢„åˆ¤ï¼š{strongest_data['max_consecutive']}è¿æ¿æ˜¾ç¤º{'å¼ºåŠ¿å»¶ç»­' if '3' in strongest_data['max_consecutive'] else 'åˆæœŸå¯åŠ¨'}
        
        ğŸ”¸ **åƒç‰›å“¥æœºä¼šåˆ¤æ–­**ï¼š
        å¤§é¢å°æ¿æ¶¨åœä»£è¡¨ä¸»åŠ›èµ„é‡‘åšå†³åšå¤šï¼Œè¿æ¿æ•ˆåº”æ˜¾è‘—ã€‚
        ä½†éœ€è­¦æƒ•é«˜ä½æ”¾é‡åˆ†åŒ–ï¼Œé€šå¸¸å¼ºåŠ¿æ¿å—æœ‰2-3å¤©æƒ¯æ€§ã€‚
        å…³é”®è§‚å¯Ÿæ˜æ—¥æ˜¯å¦æœ‰æ–°èµ„é‡‘æ¥åŠ›å’Œæ”¿ç­–å‚¬åŒ–ã€‚
        """
        
        question_text = f"ğŸ”¥ ä»Šæ—¥æœ€å¼ºæœºä¼šï¼š{strongest_sector}æ¿å—ï¼Œ{strongest_data['limit_up_count']}åªæ¶¨åœï¼Œæœ€é«˜{strongest_data['max_consecutive']}ï¼Œå°æ¿èµ„é‡‘{strongest_data['total_amount']:.1f}äº¿å…ƒã€‚è¯·é¢„æµ‹è¯¥æ¿å—æ˜æ—¥èµ°åŠ¿ï¼š"
        
        options = [
            {"id": "A", "text": "å¼ºåŠ¿å»¶ç»­ï¼Œæ˜æ—¥ç»§ç»­ä¸Šæ¶¨", "score_weight": 1.0},
            {"id": "B", "text": "é«˜ä½éœ‡è¡ï¼Œæ˜æ—¥æ¶¨è·Œäº’ç°", "score_weight": 0.8},
            {"id": "C", "text": "è·åˆ©å›åï¼Œæ˜æ—¥é€‚åº¦å›è°ƒ", "score_weight": 0.6},
            {"id": "D", "text": "è§é¡¶å›è½ï¼Œæ˜æ—¥å¤§å¹…è°ƒæ•´", "score_weight": 0.4}
        ]
        
        return PredictionQuestion(
            question_id=f"{date_str}_step3",
            step=3,
            question_text=question_text,
            options=options,
            ai_analysis=ai_analysis,
            data_source=opportunity
        )
    
    async def _generate_capital_question(self, date_str: str, market_data: Dict) -> PredictionQuestion:
        """ç”Ÿæˆèµ„é‡‘éªŒè¯é¢„æµ‹é¢˜ - å¢å¼ºç‰ˆæ¿å—èµ„é‡‘æµå‘åˆ†æ"""
        
        capital = market_data.get('step4_capital_verification', {})
        fund_direction = capital.get('fund_flow_direction', 'neutral')
        
        # è·å–å‰é¢æåˆ°çš„é‡ç‚¹è‚¡ç¥¨æ‰€å±æ¿å—
        mentioned_stocks = [
            {"name": "ä¸‡ç§‘A", "sector": "æˆ¿åœ°äº§", "flow": "å‡€æµå‡º", "amount": "-8.5äº¿"},
            {"name": "æ‹›å•†é“¶è¡Œ", "sector": "é“¶è¡Œ", "flow": "å‡€æµå‡º", "amount": "-4.2äº¿"},
            {"name": "æ¯”äºšè¿ª", "sector": "æ–°èƒ½æºæ±½è½¦", "flow": "å‡€æµå…¥", "amount": "+15.6äº¿"},
            {"name": "å®å¾·æ—¶ä»£", "sector": "æ–°èƒ½æºæ±½è½¦", "flow": "å‡€æµå…¥", "amount": "+12.3äº¿"},
            {"name": "ç§‘å¤§è®¯é£", "sector": "äººå·¥æ™ºèƒ½", "flow": "å‡€æµå…¥", "amount": "+8.7äº¿"}
        ]
        
        # æŒ‰æ¿å—æ±‡æ€»èµ„é‡‘æµå‘
        sector_fund_flow = {}
        for stock in mentioned_stocks:
            sector = stock["sector"]
            amount = float(stock["amount"].replace("+", "").replace("äº¿", ""))
            if sector not in sector_fund_flow:
                sector_fund_flow[sector] = {"net_flow": 0, "stocks": [], "flow_direction": ""}
            sector_fund_flow[sector]["net_flow"] += amount
            sector_fund_flow[sector]["stocks"].append(f"{stock['name']}({stock['amount']})")
        
        # ç¡®å®šå„æ¿å—èµ„é‡‘æµå‘è¶‹åŠ¿
        for sector, data in sector_fund_flow.items():
            if data["net_flow"] > 5:
                data["flow_direction"] = "å¼ºåŠ¿å‡€æµå…¥"
            elif data["net_flow"] > 0:
                data["flow_direction"] = "æ¸©å’Œå‡€æµå…¥"
            elif data["net_flow"] > -5:
                data["flow_direction"] = "æ¸©å’Œå‡€æµå‡º"
            else:
                data["flow_direction"] = "å¤§å¹…å‡€æµå‡º"
        
        # æ’åºï¼šæŒ‰èµ„é‡‘å‡€æµå…¥æ’åº
        sorted_sectors = sorted(sector_fund_flow.items(), key=lambda x: x[1]["net_flow"], reverse=True)
        
        # æ„å»ºæ¿å—èµ„é‡‘è¯¦æƒ…
        sector_details = []
        for sector, data in sorted_sectors:
            flow_emoji = "ğŸ”¥" if data["net_flow"] > 5 else "ğŸ“ˆ" if data["net_flow"] > 0 else "ğŸ“‰" if data["net_flow"] > -5 else "ğŸ’¥"
            sector_details.append(
                f"{flow_emoji} {sector}ï¼š{data['flow_direction']} {data['net_flow']:+.1f}äº¿\n   æ ¸å¿ƒè‚¡ç¥¨ï¼š{', '.join(data['stocks'])}"
            )
        
        ai_analysis = f"""
        ğŸ’° **æ¿å—èµ„é‡‘éªŒè¯åˆ†æ**ï¼š
        
        ğŸ“Š **é‡ç‚¹æ¿å—èµ„é‡‘æµå‘**ï¼ˆåŸºäºå‰5åªæ ¸å¿ƒè‚¡ç¥¨ï¼‰ï¼š
        {chr(10).join(sector_details)}
        
        ğŸ”¸ **èµ„é‡‘æµå‘ç‰¹å¾**ï¼š
        - æµå…¥æœ€å¼ºï¼š{sorted_sectors[0][0]}ï¼ˆ+{sorted_sectors[0][1]['net_flow']:.1f}äº¿ï¼‰
        - æµå‡ºæœ€å¤§ï¼š{sorted_sectors[-1][0]}ï¼ˆ{sorted_sectors[-1][1]['net_flow']:+.1f}äº¿ï¼‰
        - æ€»ä½“æ€åŠ¿ï¼š{fund_direction}
        
        ğŸ”¸ **åŒ—å‘èµ„é‡‘åŠ¨å‘**ï¼š
        - ä»Šæ—¥å‡€æµå…¥ï¼š+21.5äº¿å…ƒ
        - é‡ç‚¹åŠ ä»“ï¼šæ–°èƒ½æºæ±½è½¦ã€äººå·¥æ™ºèƒ½
        - é‡ç‚¹å‡ä»“ï¼šæˆ¿åœ°äº§ã€é“¶è¡Œä¼ ç»Ÿæ¿å—
        
        ğŸ”¸ **èèµ„èåˆ¸æ•°æ®**ï¼š
        - èèµ„ä½™é¢ï¼š17,845äº¿ï¼ˆ+32äº¿ï¼‰
        - èåˆ¸ä½™é¢ï¼š1,234äº¿ï¼ˆ+8äº¿ï¼‰
        - èèµ„ä¹°å…¥å æ¯”ï¼š12.3%ï¼ˆ+0.5%ï¼‰
        
        ğŸ”¸ **åƒç‰›å“¥èµ„é‡‘éªŒè¯æ³•åˆ™**ï¼š
        èµ„é‡‘æ˜¯èªæ˜é’±çš„æŠ•ç¥¨å™¨ï¼Œæ¿å—èµ„é‡‘å‡€æµå…¥æŒç»­2-3å¤©æ‰èƒ½ç¡®è®¤è¶‹åŠ¿ã€‚
        æ–°å…´æ¿å—èµ„é‡‘æµå…¥ + ä¼ ç»Ÿæ¿å—èµ„é‡‘æµå‡º = å…¸å‹çš„æ¿å—è½®åŠ¨ç‰¹å¾ã€‚
        æ˜æ—¥å…³é”®çœ‹æ–°èµ„é‡‘æ˜¯å¦ç»§ç»­æ¥åŠ›ï¼Œä»¥åŠä¼ ç»Ÿæ¿å—æ˜¯å¦æ­¢è¡€ã€‚
        """
        
        question_text = f"ğŸ’° ä»Šæ—¥æ¿å—èµ„é‡‘éªŒè¯ï¼šæ–°èƒ½æºè½¦+{sorted_sectors[0][1]['net_flow']:.1f}äº¿ï¼Œåœ°äº§{sorted_sectors[-1][1]['net_flow']:+.1f}äº¿ã€‚è¯·é¢„æµ‹æ˜æ—¥èµ„é‡‘æœ€å¯èƒ½æµå‘çš„æ¿å—æ’åºï¼ˆä»å¼ºåˆ°å¼±ï¼‰ï¼š"
        
        options = [
            {"id": "A", "text": "æ–°èƒ½æºæ±½è½¦ > äººå·¥æ™ºèƒ½ > é“¶è¡Œ > æˆ¿åœ°äº§", "score_weight": 1.0},
            {"id": "B", "text": "äººå·¥æ™ºèƒ½ > æ–°èƒ½æºæ±½è½¦ > æˆ¿åœ°äº§ > é“¶è¡Œ", "score_weight": 0.9},
            {"id": "C", "text": "é“¶è¡Œ > æˆ¿åœ°äº§ > æ–°èƒ½æºæ±½è½¦ > äººå·¥æ™ºèƒ½", "score_weight": 0.6},
            {"id": "D", "text": "æˆ¿åœ°äº§ > é“¶è¡Œ > äººå·¥æ™ºèƒ½ > æ–°èƒ½æºæ±½è½¦", "score_weight": 0.4}
        ]
        
        return PredictionQuestion(
            question_id=f"{date_str}_step4",
            step=4,
            question_text=question_text,
            options=options,
            ai_analysis=ai_analysis,
            data_source=capital
        )
    
    async def _generate_logic_question(self, date_str: str, market_data: Dict) -> PredictionQuestion:
        """ç”Ÿæˆé€»è¾‘æ ¸å¯¹é¢„æµ‹é¢˜ - å¢å¼ºç‰ˆäº‹ä»¶é©±åŠ¨å’Œæ¿å—é€»è¾‘åˆ†æ"""
        
        logic = market_data.get('step5_logic_check', {})
        events = logic.get('event_driven_opportunities', [])
        
        # æ„å»ºä¸‹æœˆé‡è¦äº‹ä»¶æ—¥å†ï¼ˆåŸºäºå¢å¼ºæ•°æ®ç®¡ç†å™¨çš„äº‹ä»¶ï¼‰
        upcoming_events = [
            {
                "date": "2025-08-14", 
                "event": "ç¬¬26å±Šç”µå­ç§‘æŠ€ä¸æœªæ¥æˆ˜ç•¥ä¼šè®®",
                "sector": "åŠå¯¼ä½“", 
                "days_ahead": 11,
                "importance": "ç‰¹é«˜",
                "expected_participants": "åä¸ºã€ä¸­èŠ¯å›½é™…ã€ç´«å…‰å±•é”",
                "policy_impact": "å›½äº§æ›¿ä»£æ”¿ç­–è¿›ä¸€æ­¥æ˜ç¡®"
            },
            {
                "date": "2025-08-17",
                "event": "2025å…¨çƒæ™ºæ…§æ•™è‚²å¤§ä¼š", 
                "sector": "åœ¨çº¿æ•™è‚²",
                "days_ahead": 14,
                "importance": "é«˜",
                "expected_participants": "å¥½æœªæ¥ã€æ–°ä¸œæ–¹åœ¨çº¿ã€ä¸­å…¬æ•™è‚²",
                "policy_impact": "æ•™è‚²æ•°å­—åŒ–è½¬å‹æ”¿ç­–å‡ºå°"
            },
            {
                "date": "2025-08-31",
                "event": "ç¬¬2å±Šä¸­å›½å›½é™…æ•°å­—ä¸æ™ºèƒ½æ±½è½¦å±•è§ˆä¼š",
                "sector": "æ–°èƒ½æºæ±½è½¦",
                "days_ahead": 28,
                "importance": "ç‰¹é«˜", 
                "expected_participants": "æ¯”äºšè¿ªã€è”šæ¥ã€ç†æƒ³æ±½è½¦",
                "policy_impact": "æ–°èƒ½æºæ±½è½¦è¡¥è´´æ”¿ç­–å»¶ç»­"
            }
        ]
        
        # é€‰æ‹©æœ€è¿‘ä¸”é‡è¦çš„äº‹ä»¶
        primary_event = upcoming_events[0]  # åŠå¯¼ä½“ä¼šè®®
        
        # åˆ†æç›¸å…³æ¿å—çš„é€»è¾‘å¼ºåº¦
        sector_logic_strength = {
            "åŠå¯¼ä½“": {
                "æ”¿ç­–æ”¯æŒåº¦": "æå¼º",
                "å›½é™…ç¯å¢ƒ": "æŒ‘æˆ˜ä¸­æœ‰æœºé‡", 
                "æŠ€æœ¯çªç ´": "å…³é”®èŠ‚ç‚¹",
                "èµ„é‡‘å…³æ³¨": "æŒç»­æµå…¥",
                "é¾™å¤´ä¼ä¸š": ["ä¸­èŠ¯å›½é™…", "éŸ¦å°”è‚¡ä»½", "å…†æ˜“åˆ›æ–°"],
                "é€»è¾‘è¯„åˆ†": 9.5
            },
            "åœ¨çº¿æ•™è‚²": {
                "æ”¿ç­–æ”¯æŒåº¦": "å¼º", 
                "å›½é™…ç¯å¢ƒ": "ç¨³å®š",
                "æŠ€æœ¯çªç ´": "AI+æ•™è‚²èåˆ",
                "èµ„é‡‘å…³æ³¨": "è°¨æ…ä¹è§‚",
                "é¾™å¤´ä¼ä¸š": ["å¥½æœªæ¥", "æ–°ä¸œæ–¹åœ¨çº¿", "ä¸­å…¬æ•™è‚²"],
                "é€»è¾‘è¯„åˆ†": 7.8
            },
            "æ–°èƒ½æºæ±½è½¦": {
                "æ”¿ç­–æ”¯æŒåº¦": "å¼º",
                "å›½é™…ç¯å¢ƒ": "ç«äº‰æ¿€çƒˆ",
                "æŠ€æœ¯çªç ´": "ç”µæ± ä¸è‡ªåŠ¨é©¾é©¶",
                "èµ„é‡‘å…³æ³¨": "é«˜åº¦å…³æ³¨",
                "é¾™å¤´ä¼ä¸š": ["æ¯”äºšè¿ª", "å®å¾·æ—¶ä»£", "è”šæ¥"],
                "é€»è¾‘è¯„åˆ†": 8.9
            }
        }
        
        # æ„å»ºäº‹ä»¶è¯¦æƒ…
        events_detail = "\n".join([
            f"ğŸ“… {event['date']} ({event['days_ahead']}å¤©å) - {event['event']}\n"
            f"   ğŸ¯ æ ¸å¿ƒæ¿å—ï¼š{event['sector']} | é‡è¦æ€§ï¼š{event['importance']}\n"
            f"   ğŸ¢ é‡ç‚¹å…¬å¸ï¼š{event['expected_participants']}\n"
            f"   ğŸ“‹ æ”¿ç­–é¢„æœŸï¼š{event['policy_impact']}"
            for event in upcoming_events
        ])
        
        # æŒ‰é€»è¾‘è¯„åˆ†æ’åºæ¿å—
        sorted_logic = sorted(sector_logic_strength.items(), key=lambda x: x[1]["é€»è¾‘è¯„åˆ†"], reverse=True)
        top_sector = sorted_logic[0][0]
        top_logic = sorted_logic[0][1]
        
        ai_analysis = f"""
        ğŸ“… **ä¸‹æœˆé‡è¦äº‹ä»¶æ—¥å†**ï¼š
        {events_detail}
        
        ğŸ”¸ **æ¿å—é€»è¾‘å¼ºåº¦æ’è¡Œ**ï¼š
        ğŸ¥‡ {sorted_logic[0][0]}ï¼š{sorted_logic[0][1]['é€»è¾‘è¯„åˆ†']}åˆ† - {sorted_logic[0][1]['æ”¿ç­–æ”¯æŒåº¦']}æ”¿ç­–æ”¯æŒ
        ğŸ¥ˆ {sorted_logic[1][0]}ï¼š{sorted_logic[1][1]['é€»è¾‘è¯„åˆ†']}åˆ† - {sorted_logic[1][1]['æŠ€æœ¯çªç ´']}
        ğŸ¥‰ {sorted_logic[2][0]}ï¼š{sorted_logic[2][1]['é€»è¾‘è¯„åˆ†']}åˆ† - {sorted_logic[2][1]['èµ„é‡‘å…³æ³¨']}
        
        ğŸ”¸ **é‡ç‚¹å…³æ³¨ï¼š{primary_event['event']}**
        - ğŸ“ ä¸¾åŠæ—¶é—´ï¼š{primary_event['date']}ï¼ˆ{primary_event['days_ahead']}å¤©åï¼‰
        - ğŸ¯ å—ç›Šæ¿å—ï¼š{primary_event['sector']}
        - ğŸ“ˆ é¾™å¤´æ ‡çš„ï¼š{', '.join(top_logic['é¾™å¤´ä¼ä¸š'])}
        - ğŸ’¡ æ”¿ç­–å‚¬åŒ–ï¼š{primary_event['policy_impact']}
        
        ğŸ”¸ **åƒç‰›å“¥é€»è¾‘æ ¸å¯¹æ³•**ï¼š
        é‡å¤§ä¼šè®®å‰7-10å¤©æ˜¯æœ€ä½³å¸ƒå±€æœŸï¼Œå‰3å¤©è¿›å…¥åŠ é€ŸæœŸã€‚
        æ”¿ç­–æ”¯æŒåº¦ + æŠ€æœ¯çªç ´ç‚¹ + èµ„é‡‘å…³æ³¨åº¦ = æ¿å—é€»è¾‘å¼ºåº¦ã€‚
        å½“å‰{top_sector}æ¿å—é€»è¾‘æœ€å¼ºï¼ˆ{top_logic['é€»è¾‘è¯„åˆ†']}åˆ†ï¼‰ï¼Œå…·å¤‡æŒç»­æ€§ã€‚
        
        ğŸ”¸ **é£é™©æç¤º**ï¼š
        ä¼šè®®ä¸¾åŠå½“å¤©å¾€å¾€æ˜¯æƒ…ç»ªé«˜ç‚¹ï¼Œéœ€è¦è­¦æƒ•"åˆ©å¥½å…‘ç°"é£é™©ã€‚
        å…³æ³¨æ”¿ç­–å…·ä½“å†…å®¹ï¼Œé¿å…é¢„æœŸè¿‡é«˜å¯¼è‡´çš„å¤±æœ›æ€§ä¸‹è·Œã€‚
        """
        
        question_text = f"ğŸ“… åŸºäºäº‹ä»¶é©±åŠ¨åˆ†æï¼š{primary_event['days_ahead']}å¤©å{primary_event['event']}ï¼Œ{top_sector}æ¿å—é€»è¾‘è¯„åˆ†{top_logic['é€»è¾‘è¯„åˆ†']}åˆ†ã€‚è¯·é¢„æµ‹æœªæ¥ä¸€å‘¨è¡¨ç°æœ€ä½³çš„æ¿å—Top3ï¼š"
        
        options = [
            {"id": "A", "text": f"{sorted_logic[0][0]} > {sorted_logic[2][0]} > {sorted_logic[1][0]}", "score_weight": 1.0},
            {"id": "B", "text": f"{sorted_logic[2][0]} > {sorted_logic[0][0]} > {sorted_logic[1][0]}", "score_weight": 0.8},
            {"id": "C", "text": f"{sorted_logic[1][0]} > {sorted_logic[0][0]} > {sorted_logic[2][0]}", "score_weight": 0.7},
            {"id": "D", "text": f"{sorted_logic[1][0]} > {sorted_logic[2][0]} > {sorted_logic[0][0]}", "score_weight": 0.5}
        ]
        
        return PredictionQuestion(
            question_id=f"{date_str}_step5",
            step=5,
            question_text=question_text,
            options=options,
            ai_analysis=ai_analysis,
            data_source=logic
        )
    
    async def _generate_portfolio_question(self, date_str: str, market_data: Dict) -> PredictionQuestion:
        """ç”ŸæˆæŠ•èµ„ç»„åˆé¢„æµ‹é¢˜ - å¢å¼ºç‰ˆæ‰‹åŠ¨è‚¡ç¥¨é¢„æµ‹è¾“å…¥"""
        
        portfolio = market_data.get('step6_portfolio_management', {})
        strategy = portfolio.get('strategy_suggestion', 'æ ¹æ®æ¿å—è½®åŠ¨é€‰æ‹©é¾™å¤´è‚¡')
        
        # ç»¼åˆå‰5æ­¥çš„åˆ†æç»“æœ
        overview = market_data.get('step1_market_overview', {})
        risk = market_data.get('step2_risk_scan', {})
        opportunity = market_data.get('step3_opportunity_scan', {})
        capital = market_data.get('step4_capital_verification', {})
        logic = market_data.get('step5_logic_check', {})
        
        # è®¡ç®—ç»¼åˆå¸‚åœºè¯„åˆ†
        market_phase = overview.get('qianniu_market_phase', 'å¹³è¡¡æœŸ')
        limit_up = overview.get('limit_up_count', 0)
        limit_down = overview.get('limit_down_count', 0)
        risk_level = risk.get('systemic_risk_level', 'medium')
        
        # é£é™©æ”¶ç›Šè¯„åˆ†ç®—æ³•
        if market_phase in ['ç–¯ç‹‚æœŸ', 'äº¢å¥‹æœŸ'] and limit_up > 30:
            market_score = 8.5
            risk_appetite = "æ¿€è¿›"
            position_suggestion = "é‡ä»“"
        elif market_phase == 'å¹³è¡¡æœŸ' and limit_up > 20:
            market_score = 7.0
            risk_appetite = "ç¨³å¥"
            position_suggestion = "ä¸­ä»“"
        elif market_phase in ['ä½è¿·æœŸ', 'ææ…ŒæœŸ']:
            market_score = 4.5
            risk_appetite = "ä¿å®ˆ"
            position_suggestion = "è½»ä»“"
        else:
            market_score = 6.0
            risk_appetite = "ä¸­æ€§"
            position_suggestion = "å¹³è¡¡ä»“"
        
        # æ¨èè‚¡ç¥¨æ± ï¼ˆåŸºäºå‰é¢åˆ†æçš„æ ¸å¿ƒæ ‡çš„ï¼‰
        recommended_stocks = [
            {"name": "æ¯”äºšè¿ª", "code": "002594", "sector": "æ–°èƒ½æºæ±½è½¦", "logic": "ç”µæ± æŠ€æœ¯+æ”¿ç­–åˆ©å¥½", "risk_level": "ä¸­"},
            {"name": "å®å¾·æ—¶ä»£", "code": "300750", "sector": "æ–°èƒ½æºæ±½è½¦", "logic": "é¾™å¤´åœ°ä½+ç‰¹æ–¯æ‹‰åˆä½œ", "risk_level": "ä¸­"},
            {"name": "ç§‘å¤§è®¯é£", "code": "002230", "sector": "äººå·¥æ™ºèƒ½", "logic": "AIå¤§æ¨¡å‹çªç ´", "risk_level": "ä¸­é«˜"},
            {"name": "ä¸­èŠ¯å›½é™…", "code": "688981", "sector": "åŠå¯¼ä½“", "logic": "å›½äº§æ›¿ä»£+äº‹ä»¶å‚¬åŒ–", "risk_level": "é«˜"},
            {"name": "éŸ¦å°”è‚¡ä»½", "code": "603501", "sector": "åŠå¯¼ä½“", "logic": "èŠ¯ç‰‡è®¾è®¡é¾™å¤´", "risk_level": "é«˜"}
        ]
        
        # é£é™©æ ‡çš„ï¼ˆéœ€è¦è§„é¿çš„ï¼‰
        risk_stocks = [
            {"name": "ä¸‡ç§‘A", "code": "000002", "sector": "æˆ¿åœ°äº§", "reason": "æ”¿ç­–è°ƒæ§é£é™©"},
            {"name": "æ‹›å•†é“¶è¡Œ", "code": "600036", "sector": "é“¶è¡Œ", "reason": "æ¯å·®æ”¶çª„å‹åŠ›"}
        ]
        
        stocks_pool_detail = "\n".join([
            f"ğŸ”¥ {stock['name']}({stock['code']}) - {stock['sector']}\n   ğŸ’¡ é€»è¾‘ï¼š{stock['logic']} | âš ï¸ é£é™©ï¼š{stock['risk_level']}"
            for stock in recommended_stocks
        ])
        
        risk_stocks_detail = "\n".join([
            f"âš ï¸ {stock['name']}({stock['code']}) - {stock['reason']}"
            for stock in risk_stocks
        ])
        
        ai_analysis = f"""
        ğŸ“‹ **åƒç‰›å“¥å…­æ­¥å¤ç›˜ç»¼åˆè¯„åˆ†**ï¼š
        
        ğŸ”¸ **ç»¼åˆå¸‚åœºè¯„åˆ†**ï¼š{market_score}/10åˆ†
        - å¸‚åœºé˜¶æ®µï¼š{market_phase}ï¼ˆæ¶¨åœ{limit_up}åªï¼Œè·Œåœ{limit_down}åªï¼‰
        - é£é™©ç­‰çº§ï¼š{risk_level}
        - æŠ•èµ„é£æ ¼ï¼š{risk_appetite}
        - å»ºè®®ä»“ä½ï¼š{position_suggestion}
        
        ğŸ”¸ **æ˜æ—¥æ ¸å¿ƒè‚¡ç¥¨æ± **ï¼ˆå»ºè®®å…³æ³¨ï¼‰ï¼š
        {stocks_pool_detail}
        
        ğŸ”¸ **é£é™©è§„é¿æ¸…å•**ï¼š
        {risk_stocks_detail}
        
        ğŸ”¸ **ä»“ä½é…ç½®å»ºè®®**ï¼š
        - æ–°èƒ½æºæ±½è½¦ï¼š30%ï¼ˆæ¯”äºšè¿ª+å®å¾·æ—¶ä»£ï¼‰
        - äººå·¥æ™ºèƒ½ï¼š25%ï¼ˆç§‘å¤§è®¯é£ä¸ºä¸»ï¼‰
        - åŠå¯¼ä½“ï¼š20%ï¼ˆä¸­èŠ¯å›½é™…+éŸ¦å°”è‚¡ä»½ï¼‰
        - ç°é‡‘å‚¨å¤‡ï¼š25%ï¼ˆç­‰å¾…æ›´å¥½æœºä¼šï¼‰
        
        ğŸ”¸ **æ“ä½œæ—¶æœº**ï¼š
        - æœ€ä½³ä¹°å…¥ï¼šå¼€ç›˜å30åˆ†é’Ÿè§‚å¯Ÿé‡èƒ½
        - æ­¢ç›ˆä½ï¼šä¸ªè‚¡+15%ï¼Œæ¿å—+20%
        - æ­¢æŸä½ï¼šä¸ªè‚¡-8%ï¼Œæ€»ä»“ä½-5%
        
        ğŸ”¸ **åƒç‰›å“¥æ ‡è®°åˆ†ç»„æ³•**ï¼š
        ğŸ’ æ ¸å¿ƒæŒä»“ï¼šæ¯”äºšè¿ªã€å®å¾·æ—¶ä»£ï¼ˆé•¿æœŸé€»è¾‘ï¼‰
        âš¡ å¼¹æ€§å“ç§ï¼šç§‘å¤§è®¯é£ã€ä¸­èŠ¯å›½é™…ï¼ˆäº‹ä»¶é©±åŠ¨ï¼‰
        ğŸ›¡ï¸ é˜²å¾¡é…ç½®ï¼šç°é‡‘25%ï¼ˆåº”å¯¹ä¸ç¡®å®šæ€§ï¼‰
        
        ğŸ”¸ **æ‰‹åŠ¨é¢„æµ‹å¥–åŠ±**ï¼š
        å¦‚æœæ‚¨å¯¹æ˜æ—¥æŸåªè‚¡ç¥¨æœ‰ç‹¬ç‰¹åˆ¤æ–­ï¼Œå¯åœ¨é€‰æ‹©åæ‰‹åŠ¨è¾“å…¥
        è‚¡ç¥¨ä»£ç å’Œé¢„æµ‹ç†ç”±ï¼Œæ­£ç¡®é¢„æµ‹å°†è·å¾—é¢å¤–10åˆ†å¥–åŠ±ï¼
        """
        
        question_text = f"ğŸ“Š å…­æ­¥å¤ç›˜ç»¼åˆè¯„åˆ†{market_score}åˆ†ï¼Œ{market_phase}é˜¶æ®µå»ºè®®{position_suggestion}ã€‚è¯·é€‰æ‹©æ˜æ—¥æœ€ä¼˜æŠ•èµ„ç­–ç•¥ï¼š"
        
        options = [
            {"id": "A", "text": f"æ¿€è¿›ç­–ç•¥ï¼šé‡ä»“æ–°èƒ½æºè½¦+AIï¼ˆ{risk_appetite}é£æ ¼é€‚é…ï¼‰", "score_weight": 1.0 if risk_appetite == "æ¿€è¿›" else 0.7},
            {"id": "B", "text": f"å‡è¡¡ç­–ç•¥ï¼šåˆ†æ•£é…ç½®æ ¸å¿ƒèµ›é“ï¼ˆ{risk_appetite}é£æ ¼é€‚é…ï¼‰", "score_weight": 1.0 if risk_appetite in ["ç¨³å¥", "ä¸­æ€§"] else 0.8},
            {"id": "C", "text": f"ä¿å®ˆç­–ç•¥ï¼šè½»ä»“ä¼˜è´¨é¾™å¤´+ç°é‡‘ï¼ˆ{risk_appetite}é£æ ¼é€‚é…ï¼‰", "score_weight": 1.0 if risk_appetite == "ä¿å®ˆ" else 0.6},
            {"id": "D", "text": "è§‚æœ›ç­–ç•¥ï¼šç©ºä»“ç­‰å¾…æ›´æ˜ç¡®ä¿¡å·", "score_weight": 0.5 if market_score > 6 else 0.8}
        ]
        
        return PredictionQuestion(
            question_id=f"{date_str}_step6",
            step=6,
            question_text=question_text,
            options=options,
            ai_analysis=ai_analysis,
            data_source=portfolio
        )
    
    async def _llm_analyze_decline_reasons(self, decline_stocks: List) -> str:
        """LLMåˆ†æä¸‹è·ŒåŸå› """
        # è¿™é‡Œåº”è¯¥è°ƒç”¨çœŸå®çš„LLM APIï¼Œç°åœ¨ç”¨æ¨¡æ‹Ÿåˆ†æ
        
        if not decline_stocks:
            return "ä»Šæ—¥å¸‚åœºæ•´ä½“è¾ƒä¸ºç¨³å®šï¼Œæ— æ˜æ˜¾ç³»ç»Ÿæ€§ä¸‹è·Œã€‚ä¸ªè‚¡è°ƒæ•´ä¸»è¦å› è·åˆ©å›åæˆ–æŠ€æœ¯æ€§è°ƒæ•´ã€‚"
        
        # æ¨¡æ‹ŸLLMåˆ†æç»“æœ
        analysis_templates = [
            "æˆ¿åœ°äº§æ¿å—å¤§å¹…ä¸‹è·Œï¼Œä¸»è¦å—æ”¿ç­–è°ƒæ§é¢„æœŸå½±å“ã€‚å¤šä¸ªé‡ç‚¹åŸå¸‚å‡ºå°é™è´­æªæ–½ï¼ŒæŠ•èµ„è€…æ‹…å¿ƒè¡Œä¸šæ™¯æ°”åº¦ä¸‹é™ã€‚",
            "é“¶è¡Œæ¿å—èµ°å¼±ï¼Œå—æ¯å·®æ”¶çª„å’Œä¿¡è´·æŠ•æ”¾æ”¾ç¼“å½±å“ã€‚å¤®è¡Œè´§å¸æ”¿ç­–è½¬å‘ä¸­æ€§ï¼Œå¸‚åœºé¢„æœŸåˆ©ç‡ä¸Šè¡Œç©ºé—´æœ‰é™ã€‚",
            "ç§‘æŠ€è‚¡å›è°ƒæ˜æ˜¾ï¼Œä¸»è¦å› å‰æœŸæ¶¨å¹…è¿‡å¤§ï¼Œè·åˆ©å›åéœ€æ±‚å¼ºçƒˆã€‚åŒæ—¶æµ·å¤–ç§‘æŠ€è‚¡èµ°å¼±ï¼Œæ‹–ç´¯Aè‚¡ç§‘æŠ€æ¿å—ã€‚",
            "æ¶ˆè´¹æ¿å—ç–²è½¯ï¼Œå—æ¶ˆè´¹æ•°æ®ä¸åŠé¢„æœŸå½±å“ã€‚CPIæ•°æ®æ˜¾ç¤ºæ¶ˆè´¹å¢é•¿æ”¾ç¼“ï¼Œå¸‚åœºå¯¹æ¶ˆè´¹å¤è‹æŒè°¨æ…æ€åº¦ã€‚"
        ]
        
        import random
        return random.choice(analysis_templates)
    
    async def _save_daily_questions(self, questions: List[PredictionQuestion]):
        """ä¿å­˜æ¯æ—¥é¢˜ç›®åˆ°æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for q in questions:
            cursor.execute('''
                INSERT OR REPLACE INTO daily_questions 
                (question_id, date, step, question_text, options, ai_analysis, market_data)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                q.question_id,
                q.question_id.split('_')[0],  # æå–æ—¥æœŸ
                q.step,
                q.question_text,
                json.dumps(q.options, ensure_ascii=False),
                q.ai_analysis,
                json.dumps(q.data_source, ensure_ascii=False) if q.data_source else None
            ))
        
        conn.commit()
        conn.close()
    
    def submit_user_predictions(self, user_id: str, date: str, predictions: List[Dict]) -> Dict:
        """æäº¤ç”¨æˆ·é¢„æµ‹"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ç¡®ä¿ç”¨æˆ·å­˜åœ¨
        cursor.execute('INSERT OR IGNORE INTO users (user_id, username) VALUES (?, ?)', 
                      (user_id, f"ç”¨æˆ·{user_id[-4:]}"))
        
        total_score = 0
        for pred in predictions:
            cursor.execute('''
                INSERT INTO user_predictions 
                (user_id, date, question_id, selected_option, confidence)
                VALUES (?, ?, ?, ?, ?)
            ''', (
                user_id, date, pred['question_id'], 
                pred['selected_option'], pred.get('confidence', 0.5)
            ))
            
            # ä¸´æ—¶è¯„åˆ†ï¼ˆå®é™…è¯„åˆ†åœ¨ç¬¬äºŒå¤©éªŒè¯ï¼‰
            temp_score = int(pred.get('confidence', 0.5) * 10)
            total_score += temp_score
        
        # æ›´æ–°ç”¨æˆ·ç»Ÿè®¡
        cursor.execute('''
            UPDATE users SET total_predictions = total_predictions + ? 
            WHERE user_id = ?
        ''', (len(predictions), user_id))
        
        conn.commit()
        conn.close()
        
        return {
            "status": "success",
            "predictions_submitted": len(predictions),
            "temporary_score": total_score,
            "message": "é¢„æµ‹å·²æäº¤ï¼Œæ˜æ—¥æ”¶ç›˜åå°†è¿›è¡ŒéªŒè¯è¯„åˆ†"
        }
    
    async def verify_predictions(self, date: str, actual_market_data: Dict) -> Dict:
        """éªŒè¯é¢„æµ‹å¹¶è¯„åˆ† - ç¬¬äºŒå¤©æ‰§è¡Œ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # è·å–å½“æ—¥æ‰€æœ‰é¢„æµ‹
        cursor.execute('''
            SELECT up.*, dq.options, dq.step 
            FROM user_predictions up
            JOIN daily_questions dq ON up.question_id = dq.question_id
            WHERE up.date = ? AND up.is_correct IS NULL
        ''', (date,))
        
        predictions = cursor.fetchall()
        verification_results = []
        
        for pred in predictions:
            user_id, pred_date, question_id, selected_option, confidence = pred[:5]
            options = json.loads(pred[5])
            step = pred[6]
            
            # æ ¹æ®å®é™…å¸‚åœºæ•°æ®è®¡ç®—æ­£ç¡®ç­”æ¡ˆ
            correct_answer = await self._calculate_correct_answer(step, actual_market_data)
            
            # è®¡ç®—å¾—åˆ†
            is_correct = selected_option == correct_answer
            score = self._calculate_score(selected_option, correct_answer, confidence, options)
            
            # æ›´æ–°é¢„æµ‹è®°å½•
            cursor.execute('''
                UPDATE user_predictions 
                SET is_correct = ?, score_earned = ?
                WHERE user_id = ? AND question_id = ?
            ''', (is_correct, score, user_id, question_id))
            
            verification_results.append({
                "user_id": user_id,
                "question_id": question_id,
                "is_correct": is_correct,
                "score": score
            })
        
        # æ›´æ–°ç”¨æˆ·æ€»ä½“ç»Ÿè®¡
        await self._update_user_statistics(date)
        
        # ç”Ÿæˆæ’è¡Œæ¦œ
        await self._generate_daily_leaderboard(date)
        
        conn.commit()
        conn.close()
        
        return {
            "verified_predictions": len(verification_results),
            "results": verification_results
        }
    
    async def _calculate_correct_answer(self, step: int, actual_data: Dict) -> str:
        """æ ¹æ®å®é™…å¸‚åœºæ•°æ®è®¡ç®—æ­£ç¡®ç­”æ¡ˆ"""
        # è¿™é‡Œå®ç°æ ¹æ®ç¬¬äºŒå¤©å®é™…æ•°æ®åˆ¤æ–­å“ªä¸ªé€‰é¡¹æ›´å‡†ç¡®
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦æ›´å¤æ‚çš„é€»è¾‘
        
        if step == 1:  # å¸‚åœºæƒ…ç»ª
            actual_limit_up = actual_data.get('limit_up_count', 0)
            if actual_limit_up > 50:
                return "A"  # æƒ…ç»ªæ›´äº¢å¥‹
            elif actual_limit_up > 30:
                return "B"  # æƒ…ç»ªç¨³å®š
            elif actual_limit_up > 15:
                return "C"  # æƒ…ç»ªé™æ¸©
            else:
                return "D"  # æƒ…ç»ªè½¬å†·
        
        # å…¶ä»–æ­¥éª¤çš„åˆ¤æ–­é€»è¾‘...
        return "A"  # ç®€åŒ–å®ç°
    
    def _calculate_score(self, selected: str, correct: str, confidence: float, options: List) -> int:
        """è®¡ç®—é¢„æµ‹å¾—åˆ†"""
        base_score = 100 if selected == correct else 0
        
        # æ‰¾åˆ°é€‰é¡¹æƒé‡
        option_weight = 0.5
        for opt in options:
            if opt['id'] == selected:
                option_weight = opt.get('score_weight', 0.5)
                break
        
        # ç»¼åˆè¯„åˆ†ï¼šæ­£ç¡®æ€§ + é€‰é¡¹è´¨é‡ + ä¿¡å¿ƒåº¦
        if selected == correct:
            score = int(base_score * option_weight * (0.5 + confidence * 0.5))
        else:
            # å³ä½¿é”™è¯¯ï¼Œæ ¹æ®é€‰é¡¹è´¨é‡ç»™äºˆéƒ¨åˆ†åˆ†æ•°
            score = int(20 * option_weight * confidence)
        
        return max(0, min(100, score))
    
    async def _update_user_statistics(self, date: str):
        """æ›´æ–°ç”¨æˆ·ç»Ÿè®¡æ•°æ®"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # è®¡ç®—æ¯ä¸ªç”¨æˆ·çš„å‡†ç¡®ç‡å’Œæ€»åˆ†
        cursor.execute('''
            SELECT user_id, 
                   COUNT(*) as total,
                   SUM(CASE WHEN is_correct = 1 THEN 1 ELSE 0 END) as correct,
                   SUM(score_earned) as total_score
            FROM user_predictions 
            WHERE date = ? AND is_correct IS NOT NULL
            GROUP BY user_id
        ''', (date,))
        
        results = cursor.fetchall()
        
        for user_id, total, correct, daily_score in results:
            accuracy = correct / total if total > 0 else 0
            
            # æ›´æ–°ç”¨æˆ·æ€»ä½“ç»Ÿè®¡
            cursor.execute('''
                UPDATE users 
                SET correct_predictions = correct_predictions + ?,
                    total_score = total_score + ?,
                    accuracy_rate = (correct_predictions + ?) * 1.0 / (total_predictions)
                WHERE user_id = ?
            ''', (correct, daily_score, correct, user_id))
            
            # æ’å…¥æ¯æ—¥æ’è¡Œæ¦œè®°å½•
            cursor.execute('''
                INSERT OR REPLACE INTO daily_leaderboard
                (date, user_id, daily_score, daily_accuracy, questions_answered)
                VALUES (?, ?, ?, ?, ?)
            ''', (date, user_id, daily_score, accuracy, total))
        
        conn.commit()
        conn.close()
    
    async def _generate_daily_leaderboard(self, date: str):
        """ç”Ÿæˆæ¯æ—¥æ’è¡Œæ¦œ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æŒ‰æ¯æ—¥å¾—åˆ†æ’åºï¼Œæ›´æ–°æ’å
        cursor.execute('''
            SELECT user_id, daily_score, daily_accuracy
            FROM daily_leaderboard 
            WHERE date = ?
            ORDER BY daily_score DESC, daily_accuracy DESC
        ''', (date,))
        
        results = cursor.fetchall()
        
        for rank, (user_id, score, accuracy) in enumerate(results, 1):
            cursor.execute('''
                UPDATE daily_leaderboard 
                SET rank_position = ?
                WHERE date = ? AND user_id = ?
            ''', (rank, date, user_id))
        
        conn.commit()
        conn.close()
    
    def get_user_profile(self, user_id: str) -> Dict:
        """è·å–ç”¨æˆ·æ¡£æ¡ˆå’Œç»Ÿè®¡"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # è·å–ç”¨æˆ·åŸºç¡€ä¿¡æ¯
        cursor.execute('SELECT * FROM users WHERE user_id = ?', (user_id,))
        user_info = cursor.fetchone()
        
        if not user_info:
            return {"error": "User not found"}
        
        # è·å–æœ€è¿‘é¢„æµ‹è®°å½•
        cursor.execute('''
            SELECT up.date, up.question_id, up.selected_option, up.is_correct, up.score_earned,
                   dq.step, dq.question_text
            FROM user_predictions up
            JOIN daily_questions dq ON up.question_id = dq.question_id
            WHERE up.user_id = ?
            ORDER BY up.created_at DESC
            LIMIT 10
        ''', (user_id,))
        
        recent_predictions = cursor.fetchall()
        
        # è·å–æ’è¡Œæ¦œä¿¡æ¯
        cursor.execute('''
            SELECT date, rank_position, daily_score, daily_accuracy
            FROM daily_leaderboard
            WHERE user_id = ?
            ORDER BY date DESC
            LIMIT 7
        ''', (user_id,))
        
        rankings = cursor.fetchall()
        
        conn.close()
        
        return {
            "user_info": {
                "user_id": user_info[0],
                "username": user_info[1],
                "total_predictions": user_info[2],
                "correct_predictions": user_info[3],
                "accuracy_rate": round(user_info[4] * 100, 1),
                "total_score": user_info[5],
                "level": user_info[6]
            },
            "recent_predictions": [
                {
                    "date": p[0],
                    "step": p[5],
                    "question": p[6][:50] + "...",
                    "selected": p[2],
                    "correct": bool(p[3]) if p[3] is not None else None,
                    "score": p[4] or 0
                } for p in recent_predictions
            ],
            "recent_rankings": [
                {
                    "date": r[0],
                    "rank": r[1],
                    "score": r[2],
                    "accuracy": round(r[3] * 100, 1) if r[3] else 0
                } for r in rankings
            ]
        }
    
    def get_leaderboard(self, date: str = None, top_n: int = 20) -> Dict:
        """è·å–æ’è¡Œæ¦œ"""
        if not date:
            date = datetime.now().strftime('%Y-%m-%d')
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # è·å–æŒ‡å®šæ—¥æœŸæ’è¡Œæ¦œ
        cursor.execute('''
            SELECT dl.rank_position, u.username, dl.daily_score, dl.daily_accuracy, 
                   dl.questions_answered, u.accuracy_rate, u.total_score
            FROM daily_leaderboard dl
            JOIN users u ON dl.user_id = u.user_id
            WHERE dl.date = ?
            ORDER BY dl.rank_position
            LIMIT ?
        ''', (date, top_n))
        
        daily_ranking = cursor.fetchall()
        
        # è·å–æ€»ç§¯åˆ†æ’è¡Œæ¦œ
        cursor.execute('''
            SELECT username, total_score, accuracy_rate, total_predictions
            FROM users
            WHERE total_predictions > 0
            ORDER BY total_score DESC, accuracy_rate DESC
            LIMIT ?
        ''', (top_n,))
        
        overall_ranking = cursor.fetchall()
        
        conn.close()
        
        return {
            "daily_leaderboard": {
                "date": date,
                "rankings": [
                    {
                        "rank": r[0],
                        "username": r[1],
                        "daily_score": r[2],
                        "daily_accuracy": round(r[3] * 100, 1) if r[3] else 0,
                        "questions_answered": r[4],
                        "overall_accuracy": round(r[5] * 100, 1) if r[5] else 0
                    } for r in daily_ranking
                ]
            },
            "overall_leaderboard": [
                {
                    "rank": i + 1,
                    "username": r[0],
                    "total_score": r[1],
                    "accuracy_rate": round(r[2] * 100, 1) if r[2] else 0,
                    "total_predictions": r[3]
                } for i, r in enumerate(overall_ranking)
            ]
        }

# æµ‹è¯•ç¤ºä¾‹
async def main():
    """æµ‹è¯•é¢„æµ‹æ¸¸æˆå¼•æ“"""
    engine = PredictionGameEngine()
    
    print("ğŸ® é¢„æµ‹æŒ‘æˆ˜æ¸¸æˆå¼•æ“æµ‹è¯•")
    print("=" * 50)
    
    # æ¨¡æ‹Ÿå¸‚åœºæ•°æ®
    mock_market_data = {
        "step1_market_overview": {
            "limit_up_count": 42,
            "limit_down_count": 6,
            "qianniu_market_phase": "äº¢å¥‹æœŸ"
        },
        "step2_risk_scan": {
            "decline_ranking": [{"name": "æŸåœ°äº§è‚¡", "change": -8.5}],
            "systemic_risk_level": "low"
        },
        "step3_opportunity_scan": {
            "concept_ranking": [{"name": "AIæ¦‚å¿µ", "change": 4.2}]
        },
        "step4_capital_verification": {
            "fund_flow_direction": "neutral"
        },
        "step5_logic_check": {
            "event_driven_opportunities": [
                {"date": "2025-08-10", "event": "AIå¤§ä¼š", "sector": "äººå·¥æ™ºèƒ½"}
            ]
        },
        "step6_portfolio_management": {
            "strategy_suggestion": "æ ¹æ®æ¿å—è½®åŠ¨é€‰æ‹©é¾™å¤´è‚¡"
        }
    }
    
    # ç”Ÿæˆæ¯æ—¥é¢„æµ‹é¢˜
    date_str = "2025-08-03"
    questions = await engine.generate_daily_questions(date_str, mock_market_data)
    
    print(f"ğŸ“ ç”Ÿæˆäº† {len(questions)} é“é¢„æµ‹é¢˜:")
    for i, q in enumerate(questions, 1):
        print(f"\n{i}. {q.question_text}")
        for opt in q.options:
            print(f"   {opt['id']}. {opt['text']}")
    
    print("\nâœ… é¢„æµ‹æ¸¸æˆå¼•æ“æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    asyncio.run(main())